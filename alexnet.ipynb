{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset link: https://drive.google.com/drive/folders/1n67sVTTzye4jtLfk8n-sa2fH2gTx5Ywt?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "DATA_DIR = \"./Dataset Korosi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    \n",
    ")\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(DATA_DIR, batch_size=32,class_mode='categorical',target_size=(150,150))   \n",
    "val_generator = train_generator = training_datagen.flow_from_directory(DATA_DIR, subset='validation', batch_size=32,class_mode='categorical',target_size=(150,150))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resep yang nemu di: https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner\n",
    "\n",
    "# model_alexnet = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(150,150,3)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "\n",
    "#     tf.keras.layers.Dense(1024,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(1024,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(3,activation='softmax')  \n",
    "# ])\n",
    "\n",
    "## resep yang nemu di: https://medium.com/swlh/alexnet-with-tensorflow-46f366559ce8\n",
    "\n",
    "model_alexnet = tf.keras.models.Sequential()\n",
    "model_alexnet.add(tf.keras.layers.experimental.preprocessing.Resizing(150, 150, interpolation=\"bilinear\", input_shape=x_train.shape[1:]))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(96, 11, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.MaxPooling2D(3, strides=2))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(256, 5, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.MaxPooling2D(3, strides=2))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(256, 3, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.Flatten())\n",
    "model_alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "model_alexnet.add(tf.keras.layers.Dropout(0.5))\n",
    "model_alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "model_alexnet.add(tf.keras.layers.Dropout(0.5))\n",
    "model_alexnet.add(tf.keras.layers.Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"alexnet.csv\", \"w\")\n",
    "f.write(\"epochs,loss,val_loss,acc,val_acc\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Wsave = model_alexnet.get_weights()\n",
    "for times in range(10):\n",
    "    epo = (times+1)*10\n",
    "    model_alexnet.set_weights(Wsave)\n",
    "    model_alexnet.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc'])\n",
    "    history = model_alexnet.fit(train_generator,validation_data=val_generator,epochs=epo, verbose = 0)\n",
    "\n",
    "    f = open(\"alexnet.csv\", \"a\")\n",
    "    f.write(\"\\n\"+str(epo)+\",\"+\n",
    "        str(history.history['loss'][-1])+\",\"+\n",
    "        str(history.history['val_loss'][-1])+\",\"+\n",
    "        str(history.history['acc'][-1])+\",\"+\n",
    "        str(history.history['val_acc'][-1])\n",
    "    )\n",
    "    f.close()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss Model')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./alexnet/loss_'+str(epo)+'.png')\n",
    "    plt.cla()\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./alexnet/acc_'+str(epo)+'.png')\n",
    "    \n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "220b59355a8dadb4ba3bf77e4f9773cad1e54b32290f811d9d316f35385cbe26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
