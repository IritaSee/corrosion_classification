{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset link: https://drive.google.com/drive/folders/1n67sVTTzye4jtLfk8n-sa2fH2gTx5Ywt?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "DATA_DIR = \"../Dataset Korosi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resep yang nemu di: https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner\n",
    "\n",
    "# model_alexnet = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(150,150,3)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "\n",
    "#     tf.keras.layers.Dense(1024,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(1024,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(3,activation='softmax')  \n",
    "# ])\n",
    "\n",
    "## resep yang nemu di: https://medium.com/swlh/alexnet-with-tensorflow-46f366559ce8\n",
    "def create_model(size):\n",
    "\n",
    "    model_alexnet = tf.keras.models.Sequential()\n",
    "    model_alexnet.add(tf.keras.layers.experimental.preprocessing.Resizing(size, size, interpolation=\"bilinear\", input_shape=(size,size,3)))\n",
    "    model_alexnet.add(tf.keras.layers.Conv2D(96, 11, strides=4, padding='same'))\n",
    "    model_alexnet.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
    "    model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "    model_alexnet.add(tf.keras.layers.MaxPooling2D(3, strides=2))\n",
    "    model_alexnet.add(tf.keras.layers.Conv2D(256, 5, strides=4, padding='same'))\n",
    "    model_alexnet.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
    "    model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "    model_alexnet.add(tf.keras.layers.MaxPooling2D(3, strides=2))\n",
    "    model_alexnet.add(tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "    model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "    model_alexnet.add(tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "    model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "    model_alexnet.add(tf.keras.layers.Conv2D(256, 3, strides=4, padding='same'))\n",
    "    model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "    model_alexnet.add(tf.keras.layers.Flatten())\n",
    "    model_alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model_alexnet.add(tf.keras.layers.Dropout(0.5))\n",
    "    model_alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model_alexnet.add(tf.keras.layers.Dropout(0.5))\n",
    "    model_alexnet.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    return model_alexnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_3 (Resizing)       (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 96)        34944     \n",
      "                                                                 \n",
      " lambda_6 (Lambda)           (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 15, 15, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 256)         614656    \n",
      "                                                                 \n",
      " lambda_7 (Lambda)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 384)         885120    \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1, 1, 384)         1327488   \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 1, 256)         884992    \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 12291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,593,475\n",
      "Trainable params: 21,593,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_alexnet = create_model(128)\n",
    "model_alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"alexnet_pengujian_batch_size.csv\", \"w\")\n",
    "f.write(\"batch_size,loss,val_loss,acc,val_acc\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"alexnet_pengujian_batch_size_model_summary.txt\", \"w\")\n",
    "f.write(\"--------==== hasil model summary dari percobaan resize ====--------\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_4 (Resizing)       (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 96)        34944     \n",
      "                                                                 \n",
      " lambda_8 (Lambda)           (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 15, 15, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 4, 4, 256)         614656    \n",
      "                                                                 \n",
      " lambda_9 (Lambda)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 1, 1, 384)         885120    \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1, 1, 384)         1327488   \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 1, 1, 256)         884992    \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 12291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,593,475\n",
      "Trainable params: 21,593,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 02:58:25.196903: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-16 02:58:25.606858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-16 02:58:31.465782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 10s - loss: 1.0947 - acc: 0.4167 - val_loss: 1.0587 - val_acc: 0.4833 - 10s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "4/4 - 6s - loss: 1.0692 - acc: 0.4333 - val_loss: 1.0448 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "4/4 - 6s - loss: 1.0355 - acc: 0.5000 - val_loss: 1.0382 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "4/4 - 7s - loss: 1.0481 - acc: 0.5000 - val_loss: 1.0384 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "4/4 - 7s - loss: 1.0282 - acc: 0.5167 - val_loss: 1.0379 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "4/4 - 7s - loss: 1.0479 - acc: 0.4500 - val_loss: 1.0386 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "4/4 - 7s - loss: 1.0823 - acc: 0.4667 - val_loss: 1.0393 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "4/4 - 7s - loss: 1.0630 - acc: 0.4833 - val_loss: 1.0412 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "4/4 - 7s - loss: 1.0519 - acc: 0.4833 - val_loss: 1.0413 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "4/4 - 7s - loss: 1.0666 - acc: 0.4833 - val_loss: 1.0456 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "4/4 - 7s - loss: 1.0430 - acc: 0.4833 - val_loss: 1.0431 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "4/4 - 7s - loss: 1.0406 - acc: 0.4833 - val_loss: 1.0393 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 13/50\n",
      "4/4 - 7s - loss: 1.0559 - acc: 0.4833 - val_loss: 1.0387 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 14/50\n",
      "4/4 - 7s - loss: 1.0428 - acc: 0.4833 - val_loss: 1.0391 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 15/50\n",
      "4/4 - 7s - loss: 1.0639 - acc: 0.4833 - val_loss: 1.0396 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 16/50\n",
      "4/4 - 7s - loss: 1.0588 - acc: 0.4833 - val_loss: 1.0399 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 17/50\n",
      "4/4 - 6s - loss: 1.0347 - acc: 0.4833 - val_loss: 1.0398 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 18/50\n",
      "4/4 - 6s - loss: 1.0395 - acc: 0.4833 - val_loss: 1.0391 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 19/50\n",
      "4/4 - 6s - loss: 1.0404 - acc: 0.4833 - val_loss: 1.0388 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 20/50\n",
      "4/4 - 6s - loss: 1.0333 - acc: 0.4833 - val_loss: 1.0382 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 21/50\n",
      "4/4 - 6s - loss: 1.0508 - acc: 0.4833 - val_loss: 1.0377 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 22/50\n",
      "4/4 - 7s - loss: 1.0489 - acc: 0.4833 - val_loss: 1.0385 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 23/50\n",
      "4/4 - 7s - loss: 1.0349 - acc: 0.4833 - val_loss: 1.0381 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 24/50\n",
      "4/4 - 7s - loss: 1.0542 - acc: 0.4833 - val_loss: 1.0382 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 25/50\n",
      "4/4 - 6s - loss: 1.0520 - acc: 0.4833 - val_loss: 1.0381 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 26/50\n",
      "4/4 - 6s - loss: 1.0371 - acc: 0.4833 - val_loss: 1.0386 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 27/50\n",
      "4/4 - 6s - loss: 1.0445 - acc: 0.4833 - val_loss: 1.0393 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 28/50\n",
      "4/4 - 6s - loss: 1.0695 - acc: 0.4833 - val_loss: 1.0402 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 29/50\n",
      "4/4 - 6s - loss: 1.0316 - acc: 0.4833 - val_loss: 1.0403 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 30/50\n",
      "4/4 - 7s - loss: 1.0423 - acc: 0.4833 - val_loss: 1.0400 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 31/50\n",
      "4/4 - 6s - loss: 1.0413 - acc: 0.4833 - val_loss: 1.0390 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 32/50\n",
      "4/4 - 6s - loss: 1.0479 - acc: 0.4833 - val_loss: 1.0382 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 33/50\n",
      "4/4 - 6s - loss: 1.0378 - acc: 0.4833 - val_loss: 1.0378 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 34/50\n",
      "4/4 - 7s - loss: 1.0511 - acc: 0.4833 - val_loss: 1.0378 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 35/50\n",
      "4/4 - 7s - loss: 1.0479 - acc: 0.4833 - val_loss: 1.0381 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 36/50\n",
      "4/4 - 6s - loss: 1.0368 - acc: 0.4833 - val_loss: 1.0384 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 37/50\n",
      "4/4 - 7s - loss: 1.0286 - acc: 0.4833 - val_loss: 1.0383 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 38/50\n",
      "4/4 - 7s - loss: 1.0453 - acc: 0.4833 - val_loss: 1.0379 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 39/50\n",
      "4/4 - 6s - loss: 1.0452 - acc: 0.4833 - val_loss: 1.0382 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 40/50\n",
      "4/4 - 7s - loss: 1.0452 - acc: 0.4833 - val_loss: 1.0391 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 41/50\n",
      "4/4 - 7s - loss: 1.0347 - acc: 0.4833 - val_loss: 1.0390 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 42/50\n",
      "4/4 - 7s - loss: 1.0387 - acc: 0.4833 - val_loss: 1.0386 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 43/50\n",
      "4/4 - 7s - loss: 1.0406 - acc: 0.4833 - val_loss: 1.0378 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 44/50\n",
      "4/4 - 7s - loss: 1.0393 - acc: 0.4833 - val_loss: 1.0376 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 45/50\n",
      "4/4 - 7s - loss: 1.0417 - acc: 0.4833 - val_loss: 1.0375 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 46/50\n",
      "4/4 - 6s - loss: 1.0445 - acc: 0.4833 - val_loss: 1.0377 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 47/50\n",
      "4/4 - 6s - loss: 1.0391 - acc: 0.4833 - val_loss: 1.0380 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 48/50\n",
      "4/4 - 7s - loss: 1.0426 - acc: 0.4833 - val_loss: 1.0387 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 49/50\n",
      "4/4 - 7s - loss: 1.0344 - acc: 0.4833 - val_loss: 1.0385 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 50/50\n",
      "4/4 - 7s - loss: 1.0381 - acc: 0.4833 - val_loss: 1.0385 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_5 (Resizing)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 56, 56, 96)        34944     \n",
      "                                                                 \n",
      " lambda_10 (Lambda)          (None, 56, 56, 96)        0         \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 56, 56, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 27, 27, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 7, 7, 256)         614656    \n",
      "                                                                 \n",
      " lambda_11 (Lambda)          (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 3, 3, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 1, 1, 384)         885120    \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 1, 1, 384)         1327488   \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 1, 256)         884992    \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 12291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,593,475\n",
      "Trainable params: 21,593,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 03:04:03.824304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-16 03:04:08.758919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 9s - loss: 1.0946 - acc: 0.3167 - val_loss: 1.0617 - val_acc: 0.4833 - 9s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "4/4 - 7s - loss: 1.1020 - acc: 0.4333 - val_loss: 1.0460 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "4/4 - 7s - loss: 1.0472 - acc: 0.4833 - val_loss: 1.0434 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "4/4 - 7s - loss: 1.0314 - acc: 0.4833 - val_loss: 1.0393 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "4/4 - 7s - loss: 1.0402 - acc: 0.4833 - val_loss: 1.0386 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "4/4 - 7s - loss: 1.0176 - acc: 0.4833 - val_loss: 1.0383 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "4/4 - 7s - loss: 1.0802 - acc: 0.4833 - val_loss: 1.0383 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "4/4 - 7s - loss: 1.0543 - acc: 0.4833 - val_loss: 1.0397 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "4/4 - 7s - loss: 1.0414 - acc: 0.4833 - val_loss: 1.0394 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "4/4 - 7s - loss: 1.0610 - acc: 0.4500 - val_loss: 1.0382 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "4/4 - 7s - loss: 1.0021 - acc: 0.4500 - val_loss: 1.0382 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "4/4 - 7s - loss: 1.0756 - acc: 0.4833 - val_loss: 1.0384 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 13/50\n",
      "4/4 - 7s - loss: 1.0982 - acc: 0.4833 - val_loss: 1.0393 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 14/50\n",
      "4/4 - 7s - loss: 1.0388 - acc: 0.4833 - val_loss: 1.0409 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 15/50\n",
      "4/4 - 7s - loss: 1.0631 - acc: 0.4833 - val_loss: 1.0428 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 16/50\n",
      "4/4 - 7s - loss: 1.0643 - acc: 0.4833 - val_loss: 1.0444 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 17/50\n",
      "4/4 - 7s - loss: 1.0525 - acc: 0.4833 - val_loss: 1.0425 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 18/50\n",
      "4/4 - 7s - loss: 1.0341 - acc: 0.4833 - val_loss: 1.0392 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 19/50\n",
      "4/4 - 7s - loss: 1.0389 - acc: 0.4833 - val_loss: 1.0391 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 20/50\n",
      "4/4 - 7s - loss: 1.0409 - acc: 0.4833 - val_loss: 1.0392 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 21/50\n",
      "4/4 - 7s - loss: 1.0381 - acc: 0.4833 - val_loss: 1.0377 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 22/50\n",
      "4/4 - 7s - loss: 1.0581 - acc: 0.4833 - val_loss: 1.0370 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 23/50\n",
      "4/4 - 7s - loss: 1.0522 - acc: 0.4833 - val_loss: 1.0378 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 24/50\n",
      "4/4 - 7s - loss: 1.0275 - acc: 0.4833 - val_loss: 1.0317 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 25/50\n",
      "4/4 - 7s - loss: 1.0179 - acc: 0.4833 - val_loss: 1.0011 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 26/50\n",
      "4/4 - 7s - loss: 0.9601 - acc: 0.4833 - val_loss: 0.9113 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 27/50\n",
      "4/4 - 7s - loss: 0.8051 - acc: 0.6667 - val_loss: 0.7973 - val_acc: 0.7500 - 7s/epoch - 2s/step\n",
      "Epoch 28/50\n",
      "4/4 - 7s - loss: 0.6097 - acc: 0.7667 - val_loss: 0.5445 - val_acc: 0.7833 - 7s/epoch - 2s/step\n",
      "Epoch 29/50\n",
      "4/4 - 7s - loss: 0.5680 - acc: 0.7167 - val_loss: 0.4961 - val_acc: 0.6833 - 7s/epoch - 2s/step\n",
      "Epoch 30/50\n",
      "4/4 - 7s - loss: 0.4377 - acc: 0.7333 - val_loss: 0.4347 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 31/50\n",
      "4/4 - 7s - loss: 0.5326 - acc: 0.7500 - val_loss: 0.3608 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 32/50\n",
      "4/4 - 7s - loss: 0.3990 - acc: 0.7833 - val_loss: 0.3505 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 33/50\n",
      "4/4 - 7s - loss: 0.3442 - acc: 0.8167 - val_loss: 0.3672 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 34/50\n",
      "4/4 - 7s - loss: 0.3937 - acc: 0.7667 - val_loss: 0.3542 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 35/50\n",
      "4/4 - 7s - loss: 0.3911 - acc: 0.7333 - val_loss: 0.3427 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 36/50\n",
      "4/4 - 7s - loss: 0.3543 - acc: 0.7833 - val_loss: 0.3676 - val_acc: 0.7833 - 7s/epoch - 2s/step\n",
      "Epoch 37/50\n",
      "4/4 - 7s - loss: 0.3641 - acc: 0.8000 - val_loss: 0.3530 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 38/50\n",
      "4/4 - 7s - loss: 0.3813 - acc: 0.7333 - val_loss: 0.3465 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 39/50\n",
      "4/4 - 7s - loss: 0.3651 - acc: 0.7667 - val_loss: 0.3483 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 40/50\n",
      "4/4 - 7s - loss: 0.3344 - acc: 0.8000 - val_loss: 0.3418 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 41/50\n",
      "4/4 - 7s - loss: 0.3807 - acc: 0.8000 - val_loss: 0.3408 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 42/50\n",
      "4/4 - 7s - loss: 0.3341 - acc: 0.8000 - val_loss: 0.3417 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 43/50\n",
      "4/4 - 8s - loss: 0.3363 - acc: 0.8000 - val_loss: 0.3427 - val_acc: 0.8000 - 8s/epoch - 2s/step\n",
      "Epoch 44/50\n",
      "4/4 - 7s - loss: 0.3482 - acc: 0.8000 - val_loss: 0.3439 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 45/50\n",
      "4/4 - 7s - loss: 0.3568 - acc: 0.8000 - val_loss: 0.3431 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 46/50\n",
      "4/4 - 7s - loss: 0.3520 - acc: 0.8000 - val_loss: 0.3425 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 47/50\n",
      "4/4 - 7s - loss: 0.3426 - acc: 0.8000 - val_loss: 0.3356 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 48/50\n",
      "4/4 - 7s - loss: 0.3352 - acc: 0.8000 - val_loss: 0.3275 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 49/50\n",
      "4/4 - 7s - loss: 0.3277 - acc: 0.8000 - val_loss: 0.3281 - val_acc: 0.8000 - 7s/epoch - 2s/step\n",
      "Epoch 50/50\n",
      "4/4 - 7s - loss: 0.6295 - acc: 0.7500 - val_loss: 0.3512 - val_acc: 0.8000 - 7s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZES = [8,16,24,32]\n",
    "size = 224\n",
    "\n",
    "for batchsize in BATCH_SIZES:\n",
    "    model_alexnet = create_model(size)\n",
    "    \n",
    "    f = open(\"alexnet_pengujian_batch_size_model_summary.txt\", \"a\")\n",
    "    f.write(\"\\n Ukuran batch: \"+str(batchsize)+\" \\n\"+\n",
    "       str(model_alexnet.summary())\n",
    "    )\n",
    "    f.close()\n",
    "\n",
    "    Wsave = model_alexnet.get_weights()\n",
    "    tf.keras.utils.plot_model(model_alexnet,to_file=str(batchsize)+\"alexnet.png\")    \n",
    "    training_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2\n",
    "        )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        \n",
    "    )\n",
    "\n",
    "    train_generator = training_datagen.flow_from_directory(DATA_DIR, batch_size=batchsize,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            target_size=(size,size))   \n",
    "    val_generator = train_generator = training_datagen.flow_from_directory(DATA_DIR, \n",
    "                                                            subset='validation', \n",
    "                                                            batch_size=batchsize,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            target_size=(size,size))\n",
    "    model_alexnet.set_weights(Wsave)\n",
    "    model_alexnet.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc'])\n",
    "    history = model_alexnet.fit(train_generator,validation_data=val_generator,epochs=50, verbose = 2)\n",
    "\n",
    "    f = open(\"alexnet_pengujian_batch_size.csv\", \"a\")\n",
    "    f.write(\"\\n\"+str(batchsize)+\",\"+\n",
    "        str(history.history['loss'][-1])+\",\"+\n",
    "        str(history.history['val_loss'][-1])+\",\"+\n",
    "        str(history.history['acc'][-1])+\",\"+\n",
    "        str(history.history['val_acc'][-1])\n",
    "    )\n",
    "    f.close()\n",
    "     \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss Model')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./alexnet/loss_'+str(batchsize)+'.png')\n",
    "    plt.cla()\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./alexnet/acc_'+str(batchsize)+'.png')\n",
    "    \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_64 (Functi  (None, 2, 2, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               2621952   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,881,475\n",
      "Trainable params: 4,847,363\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_mobilenet(size):\n",
    "\n",
    "    mobilenet = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape=(size,size,3),\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    )\n",
    "    \n",
    "    model_mobilenet = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer( input_shape=(size,size,3)),\n",
    "    mobilenet,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "    ])\n",
    "    return model_mobilenet\n",
    "\n",
    "mobilenet = create_mobilenet(64) # best mobilenet\n",
    "mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"mobilenet_pengujian_batch_size.csv\", \"w\")\n",
    "f.write(\"size,loss,val_loss,acc,val_acc\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"mobilenet_pengujian_batch_size_model_summary.txt\", \"w\")\n",
    "f.write(\"--------==== hasil model summary dari percobaan resize ====--------\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_64 (Functi  (None, 2, 2, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               2621952   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,881,475\n",
      "Trainable params: 4,847,363\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 03:17:15.244109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-16 03:17:29.108947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 19s - loss: 7.5650 - acc: 0.2333 - val_loss: 1.0991 - val_acc: 0.2000 - 19s/epoch - 5s/step\n",
      "Epoch 2/50\n",
      "4/4 - 6s - loss: 0.8776 - acc: 0.7167 - val_loss: 1.0975 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "4/4 - 6s - loss: 1.2125 - acc: 0.6667 - val_loss: 1.0976 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "4/4 - 6s - loss: 0.9066 - acc: 0.7167 - val_loss: 1.0981 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "4/4 - 6s - loss: 0.5334 - acc: 0.7333 - val_loss: 1.0974 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "4/4 - 7s - loss: 0.9634 - acc: 0.7500 - val_loss: 1.0966 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "4/4 - 6s - loss: 0.3876 - acc: 0.8500 - val_loss: 1.0958 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "4/4 - 6s - loss: 0.5809 - acc: 0.7833 - val_loss: 1.0952 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "4/4 - 6s - loss: 0.5122 - acc: 0.7667 - val_loss: 1.0938 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "4/4 - 6s - loss: 0.5807 - acc: 0.7667 - val_loss: 1.0923 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "4/4 - 6s - loss: 0.3002 - acc: 0.8667 - val_loss: 1.0906 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "4/4 - 6s - loss: 0.5380 - acc: 0.6833 - val_loss: 1.0882 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 13/50\n",
      "4/4 - 6s - loss: 0.6580 - acc: 0.7167 - val_loss: 1.0873 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 14/50\n",
      "4/4 - 6s - loss: 0.3462 - acc: 0.7500 - val_loss: 1.0862 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 15/50\n",
      "4/4 - 6s - loss: 0.3902 - acc: 0.8333 - val_loss: 1.0841 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 16/50\n",
      "4/4 - 6s - loss: 0.3550 - acc: 0.8167 - val_loss: 1.0837 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 17/50\n",
      "4/4 - 6s - loss: 0.4659 - acc: 0.8500 - val_loss: 1.0820 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 18/50\n",
      "4/4 - 6s - loss: 0.4124 - acc: 0.8333 - val_loss: 1.0804 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 19/50\n",
      "4/4 - 6s - loss: 0.4752 - acc: 0.7000 - val_loss: 1.0780 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 20/50\n",
      "4/4 - 6s - loss: 0.3458 - acc: 0.8500 - val_loss: 1.0770 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 21/50\n",
      "4/4 - 6s - loss: 0.3890 - acc: 0.8167 - val_loss: 1.0769 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 22/50\n",
      "4/4 - 6s - loss: 0.4133 - acc: 0.7500 - val_loss: 1.0765 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 23/50\n",
      "4/4 - 6s - loss: 0.3788 - acc: 0.7833 - val_loss: 1.0768 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 24/50\n",
      "4/4 - 6s - loss: 0.3065 - acc: 0.8667 - val_loss: 1.0766 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 25/50\n",
      "4/4 - 6s - loss: 0.3670 - acc: 0.8167 - val_loss: 1.0766 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 26/50\n",
      "4/4 - 6s - loss: 0.3174 - acc: 0.8333 - val_loss: 1.0758 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 27/50\n",
      "4/4 - 6s - loss: 0.2668 - acc: 0.8500 - val_loss: 1.0748 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 28/50\n",
      "4/4 - 6s - loss: 0.5841 - acc: 0.7333 - val_loss: 1.0772 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 29/50\n",
      "4/4 - 7s - loss: 0.3963 - acc: 0.8000 - val_loss: 1.0803 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 30/50\n",
      "4/4 - 6s - loss: 0.3994 - acc: 0.7833 - val_loss: 1.0784 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 31/50\n",
      "4/4 - 6s - loss: 0.3239 - acc: 0.8500 - val_loss: 1.0689 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 32/50\n",
      "4/4 - 6s - loss: 0.4812 - acc: 0.7833 - val_loss: 1.0635 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 33/50\n",
      "4/4 - 6s - loss: 0.2802 - acc: 0.8667 - val_loss: 1.0625 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 34/50\n",
      "4/4 - 6s - loss: 0.2614 - acc: 0.8500 - val_loss: 1.0625 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 35/50\n",
      "4/4 - 6s - loss: 0.2794 - acc: 0.9167 - val_loss: 1.0621 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 36/50\n",
      "4/4 - 6s - loss: 0.2653 - acc: 0.8500 - val_loss: 1.0613 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 37/50\n",
      "4/4 - 6s - loss: 0.6538 - acc: 0.7000 - val_loss: 1.0600 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 38/50\n",
      "4/4 - 6s - loss: 0.3658 - acc: 0.8000 - val_loss: 1.0594 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 39/50\n",
      "4/4 - 6s - loss: 0.2314 - acc: 0.8833 - val_loss: 1.0607 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 40/50\n",
      "4/4 - 6s - loss: 0.3085 - acc: 0.8833 - val_loss: 1.0620 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 41/50\n",
      "4/4 - 6s - loss: 0.2539 - acc: 0.9000 - val_loss: 1.0636 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 42/50\n",
      "4/4 - 6s - loss: 0.3408 - acc: 0.8667 - val_loss: 1.0649 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 43/50\n",
      "4/4 - 6s - loss: 0.2671 - acc: 0.8833 - val_loss: 1.0636 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 44/50\n",
      "4/4 - 6s - loss: 0.2482 - acc: 0.8667 - val_loss: 1.0609 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 45/50\n",
      "4/4 - 6s - loss: 0.3201 - acc: 0.8500 - val_loss: 1.0592 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 46/50\n",
      "4/4 - 6s - loss: 0.2153 - acc: 0.9000 - val_loss: 1.0587 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 47/50\n",
      "4/4 - 6s - loss: 0.3404 - acc: 0.8167 - val_loss: 1.0599 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 48/50\n",
      "4/4 - 6s - loss: 0.2086 - acc: 0.9333 - val_loss: 1.0623 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 49/50\n",
      "4/4 - 6s - loss: 0.2142 - acc: 0.8667 - val_loss: 1.0664 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 50/50\n",
      "4/4 - 6s - loss: 0.2497 - acc: 0.8667 - val_loss: 1.0678 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_128 (Funct  (None, 4, 4, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 20480)             0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 20480)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               10486272  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,745,795\n",
      "Trainable params: 12,711,683\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 03:22:44.704404: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-16 03:22:52.184261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 13s - loss: 12.8745 - acc: 0.4667 - val_loss: 1.1037 - val_acc: 0.3167 - 13s/epoch - 3s/step\n",
      "Epoch 2/50\n",
      "4/4 - 7s - loss: 2.9494 - acc: 0.7167 - val_loss: 1.0999 - val_acc: 0.2000 - 7s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "4/4 - 7s - loss: 4.4092 - acc: 0.6833 - val_loss: 1.0986 - val_acc: 0.2000 - 7s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "4/4 - 7s - loss: 4.6004 - acc: 0.7000 - val_loss: 1.0972 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "4/4 - 7s - loss: 1.9558 - acc: 0.5833 - val_loss: 1.0935 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "4/4 - 7s - loss: 1.6350 - acc: 0.7833 - val_loss: 1.0884 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "4/4 - 7s - loss: 1.1843 - acc: 0.8167 - val_loss: 1.0850 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "4/4 - 7s - loss: 1.1976 - acc: 0.8000 - val_loss: 1.0826 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "4/4 - 7s - loss: 0.9659 - acc: 0.7500 - val_loss: 1.0751 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "4/4 - 7s - loss: 0.7891 - acc: 0.7833 - val_loss: 1.0723 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "4/4 - 7s - loss: 0.6172 - acc: 0.8167 - val_loss: 1.0702 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "4/4 - 7s - loss: 1.1597 - acc: 0.8000 - val_loss: 1.0654 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 13/50\n",
      "4/4 - 7s - loss: 0.5146 - acc: 0.8500 - val_loss: 1.0566 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 14/50\n",
      "4/4 - 7s - loss: 2.6640 - acc: 0.6833 - val_loss: 1.0537 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 15/50\n",
      "4/4 - 7s - loss: 0.8291 - acc: 0.7333 - val_loss: 1.0500 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 16/50\n",
      "4/4 - 6s - loss: 0.5023 - acc: 0.7833 - val_loss: 1.0530 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 17/50\n",
      "4/4 - 7s - loss: 0.3187 - acc: 0.8167 - val_loss: 1.0535 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 18/50\n",
      "4/4 - 7s - loss: 0.9748 - acc: 0.8500 - val_loss: 1.0541 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 19/50\n",
      "4/4 - 6s - loss: 0.2864 - acc: 0.8500 - val_loss: 1.0517 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 20/50\n",
      "4/4 - 6s - loss: 0.3161 - acc: 0.7833 - val_loss: 1.0491 - val_acc: 0.4833 - 6s/epoch - 2s/step\n",
      "Epoch 21/50\n",
      "4/4 - 7s - loss: 0.7061 - acc: 0.8333 - val_loss: 1.0449 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 22/50\n",
      "4/4 - 7s - loss: 0.2608 - acc: 0.8667 - val_loss: 1.0442 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 23/50\n",
      "4/4 - 7s - loss: 0.3017 - acc: 0.8500 - val_loss: 1.0445 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 24/50\n",
      "4/4 - 7s - loss: 1.3234 - acc: 0.8167 - val_loss: 1.0476 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 25/50\n",
      "4/4 - 7s - loss: 2.7571 - acc: 0.8000 - val_loss: 1.0505 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 26/50\n",
      "4/4 - 7s - loss: 0.3749 - acc: 0.8333 - val_loss: 1.0461 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 27/50\n",
      "4/4 - 7s - loss: 1.9993 - acc: 0.7667 - val_loss: 1.0453 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 28/50\n",
      "4/4 - 7s - loss: 0.2548 - acc: 0.8500 - val_loss: 1.0409 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 29/50\n",
      "4/4 - 7s - loss: 0.9071 - acc: 0.6833 - val_loss: 1.0381 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 30/50\n",
      "4/4 - 7s - loss: 0.9795 - acc: 0.8000 - val_loss: 1.0516 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 31/50\n",
      "4/4 - 7s - loss: 0.3982 - acc: 0.8500 - val_loss: 1.0515 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 32/50\n",
      "4/4 - 7s - loss: 0.2706 - acc: 0.8333 - val_loss: 1.0519 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 33/50\n",
      "4/4 - 7s - loss: 0.2122 - acc: 0.9167 - val_loss: 1.0477 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 34/50\n",
      "4/4 - 7s - loss: 0.7254 - acc: 0.8333 - val_loss: 1.0437 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 35/50\n",
      "4/4 - 7s - loss: 7.0842 - acc: 0.7333 - val_loss: 1.0410 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 36/50\n",
      "4/4 - 7s - loss: 0.3155 - acc: 0.8833 - val_loss: 1.0435 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 37/50\n",
      "4/4 - 7s - loss: 0.7028 - acc: 0.8000 - val_loss: 1.0468 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 38/50\n",
      "4/4 - 7s - loss: 1.3629 - acc: 0.8000 - val_loss: 1.0406 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 39/50\n",
      "4/4 - 7s - loss: 0.2862 - acc: 0.8833 - val_loss: 1.0442 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 40/50\n",
      "4/4 - 7s - loss: 0.7856 - acc: 0.8667 - val_loss: 1.0426 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 41/50\n",
      "4/4 - 7s - loss: 0.3150 - acc: 0.8667 - val_loss: 1.0402 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 42/50\n",
      "4/4 - 7s - loss: 0.4394 - acc: 0.8667 - val_loss: 1.0462 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 43/50\n",
      "4/4 - 7s - loss: 0.2386 - acc: 0.9167 - val_loss: 1.0625 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 44/50\n",
      "4/4 - 7s - loss: 0.4134 - acc: 0.8500 - val_loss: 1.0569 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 45/50\n",
      "4/4 - 7s - loss: 0.2698 - acc: 0.8667 - val_loss: 1.0497 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 46/50\n",
      "4/4 - 7s - loss: 0.2381 - acc: 0.8500 - val_loss: 1.0471 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 47/50\n",
      "4/4 - 7s - loss: 0.3365 - acc: 0.7833 - val_loss: 1.0492 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 48/50\n",
      "4/4 - 7s - loss: 0.2114 - acc: 0.9167 - val_loss: 1.0499 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 49/50\n",
      "4/4 - 7s - loss: 0.2106 - acc: 0.9167 - val_loss: 1.0491 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 50/50\n",
      "4/4 - 7s - loss: 0.5563 - acc: 0.8000 - val_loss: 1.0416 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               32113152  \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,372,675\n",
      "Trainable params: 34,338,563\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 03:28:22.919505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-16 03:28:36.694661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 19s - loss: 23.1535 - acc: 0.4667 - val_loss: 1.0903 - val_acc: 0.4833 - 19s/epoch - 5s/step\n",
      "Epoch 2/50\n",
      "4/4 - 8s - loss: 7.9034 - acc: 0.6833 - val_loss: 1.0855 - val_acc: 0.4833 - 8s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "4/4 - 8s - loss: 14.0061 - acc: 0.6333 - val_loss: 1.0630 - val_acc: 0.4833 - 8s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "4/4 - 8s - loss: 6.9069 - acc: 0.7333 - val_loss: 1.0908 - val_acc: 0.4833 - 8s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "4/4 - 7s - loss: 3.6337 - acc: 0.8000 - val_loss: 1.1812 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "4/4 - 7s - loss: 5.4505 - acc: 0.7500 - val_loss: 1.3995 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "4/4 - 7s - loss: 6.2556 - acc: 0.7500 - val_loss: 1.6131 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "4/4 - 7s - loss: 3.0368 - acc: 0.7833 - val_loss: 1.6747 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "4/4 - 7s - loss: 4.4470 - acc: 0.8333 - val_loss: 1.7266 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "4/4 - 7s - loss: 2.8399 - acc: 0.7500 - val_loss: 1.9876 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "4/4 - 7s - loss: 1.9131 - acc: 0.8333 - val_loss: 2.4082 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "4/4 - 7s - loss: 6.3757 - acc: 0.7500 - val_loss: 2.1693 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 13/50\n",
      "4/4 - 7s - loss: 1.1499 - acc: 0.8167 - val_loss: 1.8802 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 14/50\n",
      "4/4 - 7s - loss: 1.0114 - acc: 0.7833 - val_loss: 1.6478 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 15/50\n",
      "4/4 - 7s - loss: 1.6733 - acc: 0.7333 - val_loss: 1.5280 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 16/50\n",
      "4/4 - 7s - loss: 1.4322 - acc: 0.7667 - val_loss: 1.4500 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 17/50\n",
      "4/4 - 7s - loss: 0.6544 - acc: 0.8500 - val_loss: 1.3944 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 18/50\n",
      "4/4 - 7s - loss: 1.2757 - acc: 0.8000 - val_loss: 1.3471 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 19/50\n",
      "4/4 - 7s - loss: 0.4110 - acc: 0.8333 - val_loss: 1.3066 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 20/50\n",
      "4/4 - 7s - loss: 1.3482 - acc: 0.8000 - val_loss: 1.2605 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 21/50\n",
      "4/4 - 7s - loss: 1.8834 - acc: 0.8000 - val_loss: 1.2145 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 22/50\n",
      "4/4 - 7s - loss: 1.1584 - acc: 0.8167 - val_loss: 1.1861 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 23/50\n",
      "4/4 - 7s - loss: 1.0240 - acc: 0.6500 - val_loss: 1.2450 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 24/50\n",
      "4/4 - 7s - loss: 0.4052 - acc: 0.8500 - val_loss: 1.3236 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 25/50\n",
      "4/4 - 8s - loss: 0.6841 - acc: 0.8167 - val_loss: 1.2424 - val_acc: 0.4833 - 8s/epoch - 2s/step\n",
      "Epoch 26/50\n",
      "4/4 - 7s - loss: 0.3657 - acc: 0.8333 - val_loss: 1.1804 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 27/50\n",
      "4/4 - 7s - loss: 0.4224 - acc: 0.8500 - val_loss: 1.3451 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 28/50\n",
      "4/4 - 7s - loss: 0.6015 - acc: 0.7833 - val_loss: 1.6708 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 29/50\n",
      "4/4 - 7s - loss: 0.3129 - acc: 0.8000 - val_loss: 1.9682 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 30/50\n",
      "4/4 - 7s - loss: 0.4384 - acc: 0.8333 - val_loss: 2.1734 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 31/50\n",
      "4/4 - 7s - loss: 0.3142 - acc: 0.8833 - val_loss: 2.2984 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 32/50\n",
      "4/4 - 8s - loss: 0.3643 - acc: 0.8167 - val_loss: 2.3818 - val_acc: 0.4833 - 8s/epoch - 2s/step\n",
      "Epoch 33/50\n",
      "4/4 - 7s - loss: 0.3983 - acc: 0.8167 - val_loss: 2.4674 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 34/50\n",
      "4/4 - 7s - loss: 0.2291 - acc: 0.8667 - val_loss: 2.5364 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 35/50\n",
      "4/4 - 7s - loss: 0.6460 - acc: 0.8167 - val_loss: 2.6104 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 36/50\n",
      "4/4 - 7s - loss: 0.3744 - acc: 0.8667 - val_loss: 2.7053 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 37/50\n",
      "4/4 - 7s - loss: 0.4047 - acc: 0.8833 - val_loss: 2.7745 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 38/50\n",
      "4/4 - 7s - loss: 0.3643 - acc: 0.9000 - val_loss: 2.8342 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 39/50\n",
      "4/4 - 7s - loss: 0.4929 - acc: 0.8333 - val_loss: 2.8970 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 40/50\n",
      "4/4 - 7s - loss: 0.3751 - acc: 0.8667 - val_loss: 2.9945 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 41/50\n",
      "4/4 - 7s - loss: 0.5110 - acc: 0.8500 - val_loss: 3.0729 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 42/50\n",
      "4/4 - 7s - loss: 0.1962 - acc: 0.8833 - val_loss: 3.1280 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 43/50\n",
      "4/4 - 7s - loss: 0.2866 - acc: 0.8500 - val_loss: 3.1792 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 44/50\n",
      "4/4 - 7s - loss: 0.2881 - acc: 0.9167 - val_loss: 3.2091 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 45/50\n",
      "4/4 - 7s - loss: 0.2295 - acc: 0.8833 - val_loss: 3.2320 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 46/50\n",
      "4/4 - 7s - loss: 0.2147 - acc: 0.9000 - val_loss: 3.2494 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 47/50\n",
      "4/4 - 7s - loss: 0.2663 - acc: 0.9000 - val_loss: 3.2933 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 48/50\n",
      "4/4 - 7s - loss: 0.5086 - acc: 0.8500 - val_loss: 3.3822 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 49/50\n",
      "4/4 - 7s - loss: 0.1482 - acc: 0.9167 - val_loss: 3.4700 - val_acc: 0.4833 - 7s/epoch - 2s/step\n",
      "Epoch 50/50\n",
      "4/4 - 7s - loss: 0.4538 - acc: 0.8333 - val_loss: 3.4229 - val_acc: 0.4833 - 7s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZES = [8,16,24,32]\n",
    "size = 64\n",
    "\n",
    "for batchsize in BATCH_SIZES:\n",
    "    mobilenet = create_mobilenet(size)\n",
    "    \n",
    "    f = open(\"mobilenet_pengujian_batch_size_model_summary.txt\", \"a\")\n",
    "    f.write(\"\\n Ukuran gambar: \"+str(batchsize)+\" \\n\"+\n",
    "       str(mobilenet.summary())\n",
    "    )\n",
    "    f.close()\n",
    "\n",
    "    Wsave = mobilenet.get_weights()\n",
    "    tf.keras.utils.plot_model(mobilenet,to_file=str(batchsize)+\"mobilenet.png\")    \n",
    "    training_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2\n",
    "        )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        \n",
    "    )\n",
    "\n",
    "    train_generator = training_datagen.flow_from_directory(DATA_DIR, batch_size=batchsize,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            target_size=(size,size))   \n",
    "    val_generator = train_generator = training_datagen.flow_from_directory(DATA_DIR, \n",
    "                                                            subset='validation', \n",
    "                                                            batch_size=batchsize,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            target_size=(size,size))\n",
    "    mobilenet.set_weights(Wsave)\n",
    "    mobilenet.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc'])\n",
    "    history = mobilenet.fit(train_generator,validation_data=val_generator,epochs=50, verbose = 2)\n",
    "\n",
    "    f = open(\"mobilenet_pengujian_batch_size.csv\", \"a\")\n",
    "    f.write(\"\\n\"+str(batchsize)+\",\"+\n",
    "        str(history.history['loss'][-1])+\",\"+\n",
    "        str(history.history['val_loss'][-1])+\",\"+\n",
    "        str(history.history['acc'][-1])+\",\"+\n",
    "        str(history.history['val_acc'][-1])\n",
    "    )\n",
    "    f.close()\n",
    "     \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss Model')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./mobilenet/loss_'+str(size)+'.png')\n",
    "    plt.cla()\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./mobilenet/acc_'+str(size)+'.png')\n",
    "    \n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "863388641bf8518efc9f9c13edbd8c5a9191560a3a7c90c25b6128b1c338502d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "220b59355a8dadb4ba3bf77e4f9773cad1e54b32290f811d9d316f35385cbe26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
