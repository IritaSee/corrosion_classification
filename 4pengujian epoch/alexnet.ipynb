{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset link: https://drive.google.com/drive/folders/1n67sVTTzye4jtLfk8n-sa2fH2gTx5Ywt?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 23:54:24.160011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-01 23:54:24.288993: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-01 23:54:24.896632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-01 23:54:24.896684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-01 23:54:24.896692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "DATA_DIR = \"../Dataset Korosi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    \n",
    ")\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(DATA_DIR, batch_size=32,class_mode='categorical',target_size=(224,224))   \n",
    "val_generator = train_generator = training_datagen.flow_from_directory(DATA_DIR, subset='validation', batch_size=32,class_mode='categorical',target_size=(224,224))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 23:54:25.736492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:25.765491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:25.765668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:25.766092: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-01 23:54:25.766483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:25.766641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:25.766779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:26.239269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:26.239447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:26.239589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-01 23:54:26.239713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4269 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "## resep yang nemu di: https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner\n",
    "\n",
    "# model_alexnet = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "\n",
    "#     tf.keras.layers.Dense(1024,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(1024,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(3,activation='softmax')  \n",
    "# ])\n",
    "\n",
    "## resep yang nemu di: https://medium.com/swlh/alexnet-with-tensorflow-46f366559ce8\n",
    "\n",
    "model_alexnet = tf.keras.models.Sequential()\n",
    "model_alexnet.add(tf.keras.layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=(224,224,3)))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(96, 11, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.MaxPooling2D(3, strides=2))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(256, 5, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Lambda(tf.nn.local_response_normalization))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.MaxPooling2D(3, strides=2))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.Conv2D(256, 3, strides=4, padding='same'))\n",
    "model_alexnet.add(tf.keras.layers.Activation('relu'))\n",
    "model_alexnet.add(tf.keras.layers.Flatten())\n",
    "model_alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "model_alexnet.add(tf.keras.layers.Dropout(0.5))\n",
    "model_alexnet.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "model_alexnet.add(tf.keras.layers.Dropout(0.5))\n",
    "model_alexnet.add(tf.keras.layers.Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 56, 56, 96)        34944     \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 56, 56, 96)        0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 56, 56, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 256)         614656    \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 384)         885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 384)         1327488   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1, 1, 384)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 256)         884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 12291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,593,475\n",
      "Trainable params: 21,593,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"alexnet.csv\", \"w\")\n",
    "f.write(\"epochs,loss,val_loss,acc,val_acc\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 23:54:32.846844: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8300\n",
      "2023-01-01 23:54:33.446680: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 9s - loss: 1.0981 - acc: 0.4500 - val_loss: 1.0969 - val_acc: 0.4833 - 9s/epoch - 4s/step\n",
      "Epoch 2/10\n",
      "2/2 - 5s - loss: 1.0971 - acc: 0.4833 - val_loss: 1.0945 - val_acc: 0.4833 - 5s/epoch - 3s/step\n",
      "Epoch 3/10\n",
      "2/2 - 6s - loss: 1.0941 - acc: 0.4833 - val_loss: 1.0915 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/10\n",
      "2/2 - 6s - loss: 1.0912 - acc: 0.5167 - val_loss: 1.0879 - val_acc: 0.5167 - 6s/epoch - 3s/step\n",
      "Epoch 5/10\n",
      "2/2 - 6s - loss: 1.0879 - acc: 0.5500 - val_loss: 1.0822 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 6/10\n",
      "2/2 - 6s - loss: 1.0801 - acc: 0.6833 - val_loss: 1.0776 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 7/10\n",
      "2/2 - 5s - loss: 1.0794 - acc: 0.6667 - val_loss: 1.0698 - val_acc: 0.7000 - 5s/epoch - 3s/step\n",
      "Epoch 8/10\n",
      "2/2 - 6s - loss: 1.0689 - acc: 0.6500 - val_loss: 1.0630 - val_acc: 0.7167 - 6s/epoch - 3s/step\n",
      "Epoch 9/10\n",
      "2/2 - 6s - loss: 1.0658 - acc: 0.6333 - val_loss: 1.0553 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 10/10\n",
      "2/2 - 6s - loss: 1.0544 - acc: 0.5333 - val_loss: 1.0475 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 1/20\n",
      "2/2 - 8s - loss: 1.0985 - acc: 0.2333 - val_loss: 1.0971 - val_acc: 0.5167 - 8s/epoch - 4s/step\n",
      "Epoch 2/20\n",
      "2/2 - 6s - loss: 1.0968 - acc: 0.5000 - val_loss: 1.0952 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/20\n",
      "2/2 - 6s - loss: 1.0945 - acc: 0.4833 - val_loss: 1.0926 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/20\n",
      "2/2 - 6s - loss: 1.0921 - acc: 0.5000 - val_loss: 1.0893 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 5/20\n",
      "2/2 - 6s - loss: 1.0890 - acc: 0.6167 - val_loss: 1.0844 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 6/20\n",
      "2/2 - 6s - loss: 1.0838 - acc: 0.6500 - val_loss: 1.0791 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 7/20\n",
      "2/2 - 6s - loss: 1.0795 - acc: 0.7000 - val_loss: 1.0715 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 8/20\n",
      "2/2 - 6s - loss: 1.0704 - acc: 0.6833 - val_loss: 1.0619 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 9/20\n",
      "2/2 - 6s - loss: 1.0619 - acc: 0.6833 - val_loss: 1.0515 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 10/20\n",
      "2/2 - 6s - loss: 1.0514 - acc: 0.7500 - val_loss: 1.0393 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 11/20\n",
      "2/2 - 6s - loss: 1.0424 - acc: 0.7500 - val_loss: 1.0190 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 12/20\n",
      "2/2 - 6s - loss: 1.0247 - acc: 0.7500 - val_loss: 0.9900 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 13/20\n",
      "2/2 - 6s - loss: 0.9859 - acc: 0.7833 - val_loss: 0.9528 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 14/20\n",
      "2/2 - 6s - loss: 0.9505 - acc: 0.7667 - val_loss: 0.8987 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 15/20\n",
      "2/2 - 6s - loss: 0.8892 - acc: 0.8000 - val_loss: 0.8135 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 16/20\n",
      "2/2 - 6s - loss: 0.8059 - acc: 0.8000 - val_loss: 0.7090 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 17/20\n",
      "2/2 - 6s - loss: 0.7159 - acc: 0.8000 - val_loss: 0.5995 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 18/20\n",
      "2/2 - 6s - loss: 0.5999 - acc: 0.7833 - val_loss: 0.5325 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 19/20\n",
      "2/2 - 6s - loss: 0.5332 - acc: 0.8000 - val_loss: 0.4556 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/20\n",
      "2/2 - 6s - loss: 0.4372 - acc: 0.8000 - val_loss: 0.4225 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 1/30\n",
      "2/2 - 8s - loss: 1.0986 - acc: 0.4000 - val_loss: 1.0973 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/30\n",
      "2/2 - 6s - loss: 1.0969 - acc: 0.4833 - val_loss: 1.0953 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/30\n",
      "2/2 - 6s - loss: 1.0952 - acc: 0.4833 - val_loss: 1.0930 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/30\n",
      "2/2 - 6s - loss: 1.0929 - acc: 0.4833 - val_loss: 1.0899 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/30\n",
      "2/2 - 6s - loss: 1.0896 - acc: 0.4833 - val_loss: 1.0863 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 6/30\n",
      "2/2 - 6s - loss: 1.0864 - acc: 0.4833 - val_loss: 1.0813 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 7/30\n",
      "2/2 - 6s - loss: 1.0806 - acc: 0.4833 - val_loss: 1.0745 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 8/30\n",
      "2/2 - 6s - loss: 1.0737 - acc: 0.4833 - val_loss: 1.0658 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 9/30\n",
      "2/2 - 5s - loss: 1.0666 - acc: 0.6667 - val_loss: 1.0569 - val_acc: 0.7833 - 5s/epoch - 3s/step\n",
      "Epoch 10/30\n",
      "2/2 - 6s - loss: 1.0550 - acc: 0.7167 - val_loss: 1.0461 - val_acc: 0.5500 - 6s/epoch - 3s/step\n",
      "Epoch 11/30\n",
      "2/2 - 6s - loss: 1.0531 - acc: 0.5500 - val_loss: 1.0336 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 12/30\n",
      "2/2 - 6s - loss: 1.0334 - acc: 0.6167 - val_loss: 1.0180 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 13/30\n",
      "2/2 - 6s - loss: 1.0142 - acc: 0.6333 - val_loss: 0.9886 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 14/30\n",
      "2/2 - 6s - loss: 0.9917 - acc: 0.7000 - val_loss: 0.9504 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 15/30\n",
      "2/2 - 6s - loss: 0.9487 - acc: 0.7333 - val_loss: 0.8945 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 16/30\n",
      "2/2 - 6s - loss: 0.8906 - acc: 0.8000 - val_loss: 0.8147 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 17/30\n",
      "2/2 - 6s - loss: 0.8042 - acc: 0.8000 - val_loss: 0.7176 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 18/30\n",
      "2/2 - 6s - loss: 0.7209 - acc: 0.8000 - val_loss: 0.6255 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 19/30\n",
      "2/2 - 6s - loss: 0.6184 - acc: 0.7833 - val_loss: 0.5397 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/30\n",
      "2/2 - 6s - loss: 0.5320 - acc: 0.8000 - val_loss: 0.4527 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/30\n",
      "2/2 - 6s - loss: 0.4750 - acc: 0.7833 - val_loss: 0.4080 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/30\n",
      "2/2 - 6s - loss: 0.4060 - acc: 0.8000 - val_loss: 0.3910 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/30\n",
      "2/2 - 6s - loss: 0.3765 - acc: 0.8000 - val_loss: 0.3448 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 24/30\n",
      "2/2 - 6s - loss: 0.3669 - acc: 0.8000 - val_loss: 0.3473 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 25/30\n",
      "2/2 - 6s - loss: 0.3404 - acc: 0.8333 - val_loss: 0.3551 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 26/30\n",
      "2/2 - 6s - loss: 0.3580 - acc: 0.8000 - val_loss: 0.3462 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 27/30\n",
      "2/2 - 6s - loss: 0.4146 - acc: 0.7833 - val_loss: 0.3918 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 28/30\n",
      "2/2 - 6s - loss: 0.6480 - acc: 0.7333 - val_loss: 0.5576 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 29/30\n",
      "2/2 - 6s - loss: 0.6033 - acc: 0.7667 - val_loss: 0.8790 - val_acc: 0.6500 - 6s/epoch - 3s/step\n",
      "Epoch 30/30\n",
      "2/2 - 6s - loss: 0.8425 - acc: 0.6500 - val_loss: 0.4602 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 1/40\n",
      "2/2 - 8s - loss: 1.0986 - acc: 0.2500 - val_loss: 1.0969 - val_acc: 0.8000 - 8s/epoch - 4s/step\n",
      "Epoch 2/40\n",
      "2/2 - 6s - loss: 1.0966 - acc: 0.5833 - val_loss: 1.0948 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/40\n",
      "2/2 - 6s - loss: 1.0942 - acc: 0.5000 - val_loss: 1.0922 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/40\n",
      "2/2 - 6s - loss: 1.0917 - acc: 0.5333 - val_loss: 1.0884 - val_acc: 0.5167 - 6s/epoch - 3s/step\n",
      "Epoch 5/40\n",
      "2/2 - 6s - loss: 1.0871 - acc: 0.6500 - val_loss: 1.0834 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 6/40\n",
      "2/2 - 6s - loss: 1.0838 - acc: 0.7000 - val_loss: 1.0764 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 7/40\n",
      "2/2 - 6s - loss: 1.0739 - acc: 0.6667 - val_loss: 1.0701 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 8/40\n",
      "2/2 - 6s - loss: 1.0723 - acc: 0.5500 - val_loss: 1.0632 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 9/40\n",
      "2/2 - 6s - loss: 1.0663 - acc: 0.6667 - val_loss: 1.0569 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 10/40\n",
      "2/2 - 6s - loss: 1.0573 - acc: 0.7167 - val_loss: 1.0507 - val_acc: 0.6500 - 6s/epoch - 3s/step\n",
      "Epoch 11/40\n",
      "2/2 - 6s - loss: 1.0481 - acc: 0.5833 - val_loss: 1.0415 - val_acc: 0.5500 - 6s/epoch - 3s/step\n",
      "Epoch 12/40\n",
      "2/2 - 6s - loss: 1.0437 - acc: 0.5667 - val_loss: 1.0286 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 13/40\n",
      "2/2 - 6s - loss: 1.0314 - acc: 0.5500 - val_loss: 1.0115 - val_acc: 0.6500 - 6s/epoch - 3s/step\n",
      "Epoch 14/40\n",
      "2/2 - 6s - loss: 1.0062 - acc: 0.6500 - val_loss: 0.9813 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 15/40\n",
      "2/2 - 6s - loss: 0.9770 - acc: 0.6333 - val_loss: 0.9358 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 16/40\n",
      "2/2 - 6s - loss: 0.9304 - acc: 0.7500 - val_loss: 0.8783 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 17/40\n",
      "2/2 - 6s - loss: 0.8712 - acc: 0.7667 - val_loss: 0.7978 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 18/40\n",
      "2/2 - 6s - loss: 0.7832 - acc: 0.7833 - val_loss: 0.6939 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 19/40\n",
      "2/2 - 6s - loss: 0.6897 - acc: 0.8000 - val_loss: 0.5766 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/40\n",
      "2/2 - 6s - loss: 0.5968 - acc: 0.7833 - val_loss: 0.4933 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/40\n",
      "2/2 - 6s - loss: 0.5225 - acc: 0.8000 - val_loss: 0.4395 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/40\n",
      "2/2 - 6s - loss: 0.4260 - acc: 0.8000 - val_loss: 0.4192 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/40\n",
      "2/2 - 6s - loss: 0.4105 - acc: 0.8000 - val_loss: 0.3794 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 24/40\n",
      "2/2 - 6s - loss: 0.3561 - acc: 0.8000 - val_loss: 0.3484 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 25/40\n",
      "2/2 - 6s - loss: 0.3555 - acc: 0.8167 - val_loss: 0.3319 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 26/40\n",
      "2/2 - 6s - loss: 0.3276 - acc: 0.8500 - val_loss: 0.3392 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 27/40\n",
      "2/2 - 6s - loss: 0.3225 - acc: 0.8667 - val_loss: 0.3178 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 28/40\n",
      "2/2 - 6s - loss: 0.3440 - acc: 0.8167 - val_loss: 0.3259 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 29/40\n",
      "2/2 - 6s - loss: 0.3325 - acc: 0.8167 - val_loss: 0.3464 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 30/40\n",
      "2/2 - 6s - loss: 0.3125 - acc: 0.8500 - val_loss: 0.3348 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 31/40\n",
      "2/2 - 6s - loss: 0.3208 - acc: 0.8333 - val_loss: 0.3154 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 32/40\n",
      "2/2 - 6s - loss: 0.3618 - acc: 0.8167 - val_loss: 0.3142 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 33/40\n",
      "2/2 - 6s - loss: 0.3293 - acc: 0.8000 - val_loss: 0.5056 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 34/40\n",
      "2/2 - 6s - loss: 0.3773 - acc: 0.8000 - val_loss: 0.3534 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 35/40\n",
      "2/2 - 6s - loss: 0.3412 - acc: 0.8333 - val_loss: 0.3600 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 36/40\n",
      "2/2 - 6s - loss: 0.3652 - acc: 0.8167 - val_loss: 0.3577 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/40\n",
      "2/2 - 6s - loss: 0.3709 - acc: 0.8000 - val_loss: 0.3726 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 38/40\n",
      "2/2 - 6s - loss: 0.3746 - acc: 0.8000 - val_loss: 0.4302 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 39/40\n",
      "2/2 - 6s - loss: 0.4247 - acc: 0.8000 - val_loss: 0.3981 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 40/40\n",
      "2/2 - 6s - loss: 0.4164 - acc: 0.8500 - val_loss: 0.3400 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 1/50\n",
      "2/2 - 8s - loss: 1.0983 - acc: 0.3667 - val_loss: 1.0969 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/50\n",
      "2/2 - 6s - loss: 1.0964 - acc: 0.4833 - val_loss: 1.0948 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/50\n",
      "2/2 - 5s - loss: 1.0944 - acc: 0.4833 - val_loss: 1.0920 - val_acc: 0.4833 - 5s/epoch - 3s/step\n",
      "Epoch 4/50\n",
      "2/2 - 6s - loss: 1.0916 - acc: 0.5000 - val_loss: 1.0881 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/50\n",
      "2/2 - 6s - loss: 1.0874 - acc: 0.5833 - val_loss: 1.0829 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 6/50\n",
      "2/2 - 6s - loss: 1.0840 - acc: 0.6500 - val_loss: 1.0767 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 7/50\n",
      "2/2 - 6s - loss: 1.0780 - acc: 0.7667 - val_loss: 1.0680 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 8/50\n",
      "2/2 - 6s - loss: 1.0679 - acc: 0.7000 - val_loss: 1.0580 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 9/50\n",
      "2/2 - 6s - loss: 1.0610 - acc: 0.7500 - val_loss: 1.0470 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 10/50\n",
      "2/2 - 6s - loss: 1.0581 - acc: 0.6667 - val_loss: 1.0353 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 11/50\n",
      "2/2 - 6s - loss: 1.0331 - acc: 0.7667 - val_loss: 1.0167 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 12/50\n",
      "2/2 - 6s - loss: 1.0116 - acc: 0.8000 - val_loss: 0.9838 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 13/50\n",
      "2/2 - 5s - loss: 0.9834 - acc: 0.8000 - val_loss: 0.9467 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 14/50\n",
      "2/2 - 5s - loss: 0.9392 - acc: 0.8000 - val_loss: 0.8823 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 15/50\n",
      "2/2 - 6s - loss: 0.8899 - acc: 0.7833 - val_loss: 0.8059 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 16/50\n",
      "2/2 - 6s - loss: 0.8123 - acc: 0.8000 - val_loss: 0.7198 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 17/50\n",
      "2/2 - 6s - loss: 0.7132 - acc: 0.8000 - val_loss: 0.6408 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 18/50\n",
      "2/2 - 6s - loss: 0.6162 - acc: 0.7833 - val_loss: 0.5466 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 19/50\n",
      "2/2 - 6s - loss: 0.5439 - acc: 0.8000 - val_loss: 0.4572 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/50\n",
      "2/2 - 6s - loss: 0.4539 - acc: 0.8000 - val_loss: 0.4429 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/50\n",
      "2/2 - 6s - loss: 0.4159 - acc: 0.8000 - val_loss: 0.4427 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/50\n",
      "2/2 - 5s - loss: 0.4074 - acc: 0.8000 - val_loss: 0.4192 - val_acc: 0.7833 - 5s/epoch - 3s/step\n",
      "Epoch 23/50\n",
      "2/2 - 6s - loss: 0.4400 - acc: 0.7833 - val_loss: 0.3444 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 24/50\n",
      "2/2 - 6s - loss: 0.4005 - acc: 0.7667 - val_loss: 0.3741 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 25/50\n",
      "2/2 - 6s - loss: 0.3843 - acc: 0.8000 - val_loss: 0.4566 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 26/50\n",
      "2/2 - 5s - loss: 0.4900 - acc: 0.8000 - val_loss: 0.3398 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 27/50\n",
      "2/2 - 5s - loss: 0.3835 - acc: 0.8000 - val_loss: 0.4157 - val_acc: 0.7833 - 5s/epoch - 3s/step\n",
      "Epoch 28/50\n",
      "2/2 - 6s - loss: 0.3970 - acc: 0.7667 - val_loss: 0.3729 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 29/50\n",
      "2/2 - 6s - loss: 0.3797 - acc: 0.8167 - val_loss: 0.4031 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 30/50\n",
      "2/2 - 6s - loss: 0.4058 - acc: 0.8000 - val_loss: 0.3622 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 31/50\n",
      "2/2 - 6s - loss: 0.3430 - acc: 0.8500 - val_loss: 0.3668 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 32/50\n",
      "2/2 - 6s - loss: 0.3759 - acc: 0.8167 - val_loss: 0.3514 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/50\n",
      "2/2 - 6s - loss: 0.3571 - acc: 0.8167 - val_loss: 0.3256 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 34/50\n",
      "2/2 - 5s - loss: 0.3500 - acc: 0.8333 - val_loss: 0.3496 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 35/50\n",
      "2/2 - 6s - loss: 0.3362 - acc: 0.8333 - val_loss: 0.3574 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 36/50\n",
      "2/2 - 6s - loss: 0.3230 - acc: 0.8167 - val_loss: 0.3208 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 37/50\n",
      "2/2 - 6s - loss: 0.3369 - acc: 0.8500 - val_loss: 0.3395 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 38/50\n",
      "2/2 - 6s - loss: 0.3420 - acc: 0.8167 - val_loss: 0.3351 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 39/50\n",
      "2/2 - 6s - loss: 0.3400 - acc: 0.8167 - val_loss: 0.3279 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 40/50\n",
      "2/2 - 6s - loss: 0.3404 - acc: 0.8167 - val_loss: 0.3194 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 41/50\n",
      "2/2 - 5s - loss: 0.3569 - acc: 0.8000 - val_loss: 0.3242 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 42/50\n",
      "2/2 - 6s - loss: 0.3288 - acc: 0.8333 - val_loss: 0.3225 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 43/50\n",
      "2/2 - 6s - loss: 0.3243 - acc: 0.8333 - val_loss: 0.3169 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 44/50\n",
      "2/2 - 6s - loss: 0.3138 - acc: 0.8500 - val_loss: 0.3253 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 45/50\n",
      "2/2 - 6s - loss: 0.3170 - acc: 0.8333 - val_loss: 0.3086 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 46/50\n",
      "2/2 - 6s - loss: 0.3122 - acc: 0.8500 - val_loss: 0.3259 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 47/50\n",
      "2/2 - 6s - loss: 0.3165 - acc: 0.8667 - val_loss: 0.3402 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 48/50\n",
      "2/2 - 6s - loss: 0.3304 - acc: 0.8333 - val_loss: 0.3105 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 49/50\n",
      "2/2 - 6s - loss: 0.3207 - acc: 0.8167 - val_loss: 0.3211 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 50/50\n",
      "2/2 - 6s - loss: 0.3197 - acc: 0.8667 - val_loss: 0.3201 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 1/60\n",
      "2/2 - 8s - loss: 1.0983 - acc: 0.4667 - val_loss: 1.0970 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/60\n",
      "2/2 - 6s - loss: 1.0965 - acc: 0.4833 - val_loss: 1.0948 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/60\n",
      "2/2 - 6s - loss: 1.0944 - acc: 0.4833 - val_loss: 1.0920 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/60\n",
      "2/2 - 6s - loss: 1.0912 - acc: 0.4833 - val_loss: 1.0882 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/60\n",
      "2/2 - 6s - loss: 1.0882 - acc: 0.5667 - val_loss: 1.0835 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 6/60\n",
      "2/2 - 6s - loss: 1.0832 - acc: 0.6333 - val_loss: 1.0766 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 7/60\n",
      "2/2 - 6s - loss: 1.0738 - acc: 0.6667 - val_loss: 1.0700 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 8/60\n",
      "2/2 - 6s - loss: 1.0715 - acc: 0.6333 - val_loss: 1.0626 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 9/60\n",
      "2/2 - 6s - loss: 1.0657 - acc: 0.6000 - val_loss: 1.0562 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 10/60\n",
      "2/2 - 6s - loss: 1.0525 - acc: 0.5167 - val_loss: 1.0485 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 11/60\n",
      "2/2 - 6s - loss: 1.0501 - acc: 0.5500 - val_loss: 1.0380 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 12/60\n",
      "2/2 - 6s - loss: 1.0358 - acc: 0.5667 - val_loss: 1.0252 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 13/60\n",
      "2/2 - 6s - loss: 1.0308 - acc: 0.6000 - val_loss: 1.0052 - val_acc: 0.6333 - 6s/epoch - 3s/step\n",
      "Epoch 14/60\n",
      "2/2 - 6s - loss: 1.0021 - acc: 0.6500 - val_loss: 0.9755 - val_acc: 0.6333 - 6s/epoch - 3s/step\n",
      "Epoch 15/60\n",
      "2/2 - 6s - loss: 0.9718 - acc: 0.6500 - val_loss: 0.9311 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 16/60\n",
      "2/2 - 6s - loss: 0.9192 - acc: 0.7667 - val_loss: 0.8630 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 17/60\n",
      "2/2 - 6s - loss: 0.8536 - acc: 0.7667 - val_loss: 0.7721 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 18/60\n",
      "2/2 - 6s - loss: 0.7643 - acc: 0.7667 - val_loss: 0.6581 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 19/60\n",
      "2/2 - 6s - loss: 0.6636 - acc: 0.7833 - val_loss: 0.5900 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 20/60\n",
      "2/2 - 6s - loss: 0.5746 - acc: 0.7500 - val_loss: 0.4760 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/60\n",
      "2/2 - 6s - loss: 0.4708 - acc: 0.8000 - val_loss: 0.4166 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/60\n",
      "2/2 - 6s - loss: 0.4091 - acc: 0.8000 - val_loss: 0.3966 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/60\n",
      "2/2 - 6s - loss: 0.3741 - acc: 0.8000 - val_loss: 0.3845 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 24/60\n",
      "2/2 - 6s - loss: 0.3696 - acc: 0.8000 - val_loss: 0.3578 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/60\n",
      "2/2 - 6s - loss: 0.4036 - acc: 0.7833 - val_loss: 0.3373 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 26/60\n",
      "2/2 - 6s - loss: 0.3524 - acc: 0.8167 - val_loss: 0.3373 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 27/60\n",
      "2/2 - 5s - loss: 0.3422 - acc: 0.8167 - val_loss: 0.3986 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 28/60\n",
      "2/2 - 6s - loss: 0.3838 - acc: 0.8167 - val_loss: 0.3206 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 29/60\n",
      "2/2 - 6s - loss: 0.3712 - acc: 0.7833 - val_loss: 0.3374 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 30/60\n",
      "2/2 - 6s - loss: 0.3465 - acc: 0.8167 - val_loss: 0.3476 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 31/60\n",
      "2/2 - 6s - loss: 0.3699 - acc: 0.8000 - val_loss: 0.3411 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 32/60\n",
      "2/2 - 6s - loss: 0.3445 - acc: 0.8000 - val_loss: 0.3421 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/60\n",
      "2/2 - 6s - loss: 0.3413 - acc: 0.8167 - val_loss: 0.3276 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 34/60\n",
      "2/2 - 6s - loss: 0.3310 - acc: 0.8167 - val_loss: 0.3281 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 35/60\n",
      "2/2 - 6s - loss: 0.3393 - acc: 0.8000 - val_loss: 0.3304 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 36/60\n",
      "2/2 - 6s - loss: 0.3393 - acc: 0.8167 - val_loss: 0.3421 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/60\n",
      "2/2 - 5s - loss: 0.3942 - acc: 0.7833 - val_loss: 0.3233 - val_acc: 0.8167 - 5s/epoch - 3s/step\n",
      "Epoch 38/60\n",
      "2/2 - 6s - loss: 0.3685 - acc: 0.7833 - val_loss: 0.3489 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 39/60\n",
      "2/2 - 6s - loss: 0.3350 - acc: 0.8167 - val_loss: 0.3210 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 40/60\n",
      "2/2 - 6s - loss: 0.3361 - acc: 0.8167 - val_loss: 0.3436 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 41/60\n",
      "2/2 - 6s - loss: 0.3405 - acc: 0.8167 - val_loss: 0.3388 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 42/60\n",
      "2/2 - 6s - loss: 0.3246 - acc: 0.8333 - val_loss: 0.3202 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 43/60\n",
      "2/2 - 6s - loss: 0.3344 - acc: 0.8167 - val_loss: 0.3645 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 44/60\n",
      "2/2 - 6s - loss: 0.3297 - acc: 0.8167 - val_loss: 0.3798 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 45/60\n",
      "2/2 - 6s - loss: 0.3736 - acc: 0.8167 - val_loss: 0.3312 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 46/60\n",
      "2/2 - 6s - loss: 0.3311 - acc: 0.8500 - val_loss: 0.3510 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 47/60\n",
      "2/2 - 6s - loss: 0.3561 - acc: 0.8167 - val_loss: 0.3599 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 48/60\n",
      "2/2 - 6s - loss: 0.3538 - acc: 0.8167 - val_loss: 0.3181 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 49/60\n",
      "2/2 - 6s - loss: 0.3245 - acc: 0.8167 - val_loss: 0.3536 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 50/60\n",
      "2/2 - 6s - loss: 0.3501 - acc: 0.8167 - val_loss: 0.3240 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 51/60\n",
      "2/2 - 6s - loss: 0.3151 - acc: 0.8167 - val_loss: 0.3188 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 52/60\n",
      "2/2 - 6s - loss: 0.3440 - acc: 0.8167 - val_loss: 0.3347 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 53/60\n",
      "2/2 - 6s - loss: 0.3344 - acc: 0.8167 - val_loss: 0.3278 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 54/60\n",
      "2/2 - 6s - loss: 0.3293 - acc: 0.8167 - val_loss: 0.3230 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 55/60\n",
      "2/2 - 6s - loss: 0.3104 - acc: 0.8500 - val_loss: 0.3212 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 56/60\n",
      "2/2 - 6s - loss: 0.3304 - acc: 0.8167 - val_loss: 0.3307 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 57/60\n",
      "2/2 - 6s - loss: 0.3115 - acc: 0.8167 - val_loss: 0.3161 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 58/60\n",
      "2/2 - 6s - loss: 0.3239 - acc: 0.8167 - val_loss: 0.3267 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 59/60\n",
      "2/2 - 6s - loss: 0.3070 - acc: 0.8667 - val_loss: 0.3073 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 60/60\n",
      "2/2 - 6s - loss: 0.3480 - acc: 0.8333 - val_loss: 0.3185 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 1/70\n",
      "2/2 - 7s - loss: 1.0985 - acc: 0.3667 - val_loss: 1.0966 - val_acc: 0.4833 - 7s/epoch - 4s/step\n",
      "Epoch 2/70\n",
      "2/2 - 6s - loss: 1.0962 - acc: 0.5000 - val_loss: 1.0946 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/70\n",
      "2/2 - 6s - loss: 1.0939 - acc: 0.4833 - val_loss: 1.0916 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/70\n",
      "2/2 - 5s - loss: 1.0914 - acc: 0.5167 - val_loss: 1.0879 - val_acc: 0.5000 - 5s/epoch - 3s/step\n",
      "Epoch 5/70\n",
      "2/2 - 6s - loss: 1.0874 - acc: 0.5667 - val_loss: 1.0831 - val_acc: 0.5167 - 6s/epoch - 3s/step\n",
      "Epoch 6/70\n",
      "2/2 - 6s - loss: 1.0833 - acc: 0.6000 - val_loss: 1.0766 - val_acc: 0.6333 - 6s/epoch - 3s/step\n",
      "Epoch 7/70\n",
      "2/2 - 6s - loss: 1.0767 - acc: 0.6333 - val_loss: 1.0698 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 8/70\n",
      "2/2 - 6s - loss: 1.0689 - acc: 0.6833 - val_loss: 1.0607 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 9/70\n",
      "2/2 - 6s - loss: 1.0604 - acc: 0.6000 - val_loss: 1.0508 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 10/70\n",
      "2/2 - 6s - loss: 1.0499 - acc: 0.6667 - val_loss: 1.0410 - val_acc: 0.7167 - 6s/epoch - 3s/step\n",
      "Epoch 11/70\n",
      "2/2 - 6s - loss: 1.0394 - acc: 0.6667 - val_loss: 1.0204 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 12/70\n",
      "2/2 - 6s - loss: 1.0186 - acc: 0.7667 - val_loss: 0.9923 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 13/70\n",
      "2/2 - 6s - loss: 0.9855 - acc: 0.7500 - val_loss: 0.9486 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 14/70\n",
      "2/2 - 6s - loss: 0.9465 - acc: 0.8000 - val_loss: 0.8832 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 15/70\n",
      "2/2 - 6s - loss: 0.8829 - acc: 0.7667 - val_loss: 0.7954 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 16/70\n",
      "2/2 - 6s - loss: 0.8038 - acc: 0.8000 - val_loss: 0.7039 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 17/70\n",
      "2/2 - 6s - loss: 0.6827 - acc: 0.7833 - val_loss: 0.6064 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 18/70\n",
      "2/2 - 6s - loss: 0.6184 - acc: 0.7833 - val_loss: 0.5108 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 19/70\n",
      "2/2 - 6s - loss: 0.5186 - acc: 0.8000 - val_loss: 0.4631 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/70\n",
      "2/2 - 6s - loss: 0.4494 - acc: 0.7833 - val_loss: 0.4317 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/70\n",
      "2/2 - 6s - loss: 0.4157 - acc: 0.8000 - val_loss: 0.3708 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/70\n",
      "2/2 - 6s - loss: 0.3768 - acc: 0.8167 - val_loss: 0.3483 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 23/70\n",
      "2/2 - 6s - loss: 0.3623 - acc: 0.8000 - val_loss: 0.3330 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 24/70\n",
      "2/2 - 6s - loss: 0.3669 - acc: 0.7833 - val_loss: 0.4074 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/70\n",
      "2/2 - 6s - loss: 0.3793 - acc: 0.8000 - val_loss: 0.3450 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 26/70\n",
      "2/2 - 6s - loss: 0.3561 - acc: 0.8000 - val_loss: 0.3227 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 27/70\n",
      "2/2 - 6s - loss: 0.3374 - acc: 0.8167 - val_loss: 0.3217 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 28/70\n",
      "2/2 - 6s - loss: 0.3222 - acc: 0.8000 - val_loss: 0.3413 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 29/70\n",
      "2/2 - 6s - loss: 0.4428 - acc: 0.8500 - val_loss: 0.3184 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 30/70\n",
      "2/2 - 6s - loss: 0.3173 - acc: 0.8667 - val_loss: 0.5405 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 31/70\n",
      "2/2 - 6s - loss: 0.4928 - acc: 0.7333 - val_loss: 0.6315 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 32/70\n",
      "2/2 - 6s - loss: 0.5354 - acc: 0.7667 - val_loss: 0.4020 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/70\n",
      "2/2 - 6s - loss: 0.3719 - acc: 0.7833 - val_loss: 0.3443 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 34/70\n",
      "2/2 - 6s - loss: 0.4061 - acc: 0.7833 - val_loss: 0.4119 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 35/70\n",
      "2/2 - 6s - loss: 0.3714 - acc: 0.8000 - val_loss: 0.3155 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 36/70\n",
      "2/2 - 6s - loss: 0.3160 - acc: 0.8667 - val_loss: 0.4142 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/70\n",
      "2/2 - 6s - loss: 0.4334 - acc: 0.7833 - val_loss: 0.3384 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 38/70\n",
      "2/2 - 6s - loss: 0.3198 - acc: 0.8500 - val_loss: 0.3311 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 39/70\n",
      "2/2 - 6s - loss: 0.3441 - acc: 0.8167 - val_loss: 0.3947 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 40/70\n",
      "2/2 - 6s - loss: 0.3847 - acc: 0.8000 - val_loss: 0.3262 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 41/70\n",
      "2/2 - 6s - loss: 0.3297 - acc: 0.8333 - val_loss: 0.3212 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 42/70\n",
      "2/2 - 6s - loss: 0.3793 - acc: 0.8000 - val_loss: 0.3504 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 43/70\n",
      "2/2 - 6s - loss: 0.3491 - acc: 0.8167 - val_loss: 0.3389 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 44/70\n",
      "2/2 - 6s - loss: 0.3197 - acc: 0.8667 - val_loss: 0.3144 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 45/70\n",
      "2/2 - 6s - loss: 0.3285 - acc: 0.8333 - val_loss: 0.3417 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 46/70\n",
      "2/2 - 6s - loss: 0.3556 - acc: 0.8167 - val_loss: 0.3282 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 47/70\n",
      "2/2 - 6s - loss: 0.3266 - acc: 0.8000 - val_loss: 0.3232 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 48/70\n",
      "2/2 - 6s - loss: 0.3413 - acc: 0.8167 - val_loss: 0.3262 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 49/70\n",
      "2/2 - 6s - loss: 0.3077 - acc: 0.8667 - val_loss: 0.3307 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 50/70\n",
      "2/2 - 6s - loss: 0.3263 - acc: 0.8500 - val_loss: 0.3308 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 51/70\n",
      "2/2 - 6s - loss: 0.3319 - acc: 0.8167 - val_loss: 0.3093 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 52/70\n",
      "2/2 - 6s - loss: 0.3146 - acc: 0.8333 - val_loss: 0.3204 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 53/70\n",
      "2/2 - 6s - loss: 0.3162 - acc: 0.8333 - val_loss: 0.3040 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 54/70\n",
      "2/2 - 6s - loss: 0.3181 - acc: 0.8333 - val_loss: 0.2993 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 55/70\n",
      "2/2 - 6s - loss: 0.3073 - acc: 0.8333 - val_loss: 0.3107 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 56/70\n",
      "2/2 - 6s - loss: 0.3250 - acc: 0.8667 - val_loss: 0.3156 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 57/70\n",
      "2/2 - 6s - loss: 0.3083 - acc: 0.8333 - val_loss: 0.2924 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 58/70\n",
      "2/2 - 5s - loss: 0.3073 - acc: 0.8667 - val_loss: 0.3124 - val_acc: 0.8500 - 5s/epoch - 3s/step\n",
      "Epoch 59/70\n",
      "2/2 - 6s - loss: 0.3093 - acc: 0.8333 - val_loss: 0.3128 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 60/70\n",
      "2/2 - 6s - loss: 0.2992 - acc: 0.8333 - val_loss: 0.3196 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 61/70\n",
      "2/2 - 6s - loss: 0.2951 - acc: 0.8667 - val_loss: 0.2977 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 62/70\n",
      "2/2 - 6s - loss: 0.3344 - acc: 0.8333 - val_loss: 0.3051 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 63/70\n",
      "2/2 - 6s - loss: 0.3265 - acc: 0.8167 - val_loss: 0.2985 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 64/70\n",
      "2/2 - 6s - loss: 0.3411 - acc: 0.8333 - val_loss: 0.2981 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 65/70\n",
      "2/2 - 6s - loss: 0.2977 - acc: 0.8333 - val_loss: 0.3044 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 66/70\n",
      "2/2 - 6s - loss: 0.3043 - acc: 0.8833 - val_loss: 0.2956 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 67/70\n",
      "2/2 - 5s - loss: 0.3399 - acc: 0.8333 - val_loss: 0.3015 - val_acc: 0.8667 - 5s/epoch - 3s/step\n",
      "Epoch 68/70\n",
      "2/2 - 6s - loss: 0.2768 - acc: 0.8833 - val_loss: 0.2934 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 69/70\n",
      "2/2 - 6s - loss: 0.3289 - acc: 0.8167 - val_loss: 0.3240 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 70/70\n",
      "2/2 - 6s - loss: 0.3347 - acc: 0.8167 - val_loss: 0.3022 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 1/80\n",
      "2/2 - 8s - loss: 1.0984 - acc: 0.4833 - val_loss: 1.0966 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/80\n",
      "2/2 - 6s - loss: 1.0962 - acc: 0.5000 - val_loss: 1.0946 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/80\n",
      "2/2 - 6s - loss: 1.0946 - acc: 0.4833 - val_loss: 1.0916 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/80\n",
      "2/2 - 6s - loss: 1.0909 - acc: 0.5000 - val_loss: 1.0879 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/80\n",
      "2/2 - 6s - loss: 1.0871 - acc: 0.5000 - val_loss: 1.0832 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 6/80\n",
      "2/2 - 6s - loss: 1.0817 - acc: 0.5667 - val_loss: 1.0769 - val_acc: 0.5833 - 6s/epoch - 3s/step\n",
      "Epoch 7/80\n",
      "2/2 - 6s - loss: 1.0780 - acc: 0.6000 - val_loss: 1.0697 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 8/80\n",
      "2/2 - 6s - loss: 1.0711 - acc: 0.5667 - val_loss: 1.0634 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 9/80\n",
      "2/2 - 6s - loss: 1.0604 - acc: 0.5167 - val_loss: 1.0567 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 10/80\n",
      "2/2 - 6s - loss: 1.0590 - acc: 0.5000 - val_loss: 1.0516 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 11/80\n",
      "2/2 - 6s - loss: 1.0525 - acc: 0.4833 - val_loss: 1.0436 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 12/80\n",
      "2/2 - 6s - loss: 1.0484 - acc: 0.4833 - val_loss: 1.0303 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 13/80\n",
      "2/2 - 6s - loss: 1.0285 - acc: 0.4833 - val_loss: 1.0110 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 14/80\n",
      "2/2 - 6s - loss: 1.0016 - acc: 0.5167 - val_loss: 0.9823 - val_acc: 0.5500 - 6s/epoch - 3s/step\n",
      "Epoch 15/80\n",
      "2/2 - 6s - loss: 0.9872 - acc: 0.5167 - val_loss: 0.9431 - val_acc: 0.7167 - 6s/epoch - 3s/step\n",
      "Epoch 16/80\n",
      "2/2 - 6s - loss: 0.9463 - acc: 0.7500 - val_loss: 0.8848 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 17/80\n",
      "2/2 - 6s - loss: 0.8870 - acc: 0.7000 - val_loss: 0.8200 - val_acc: 0.7167 - 6s/epoch - 3s/step\n",
      "Epoch 18/80\n",
      "2/2 - 6s - loss: 0.8116 - acc: 0.7667 - val_loss: 0.7158 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 19/80\n",
      "2/2 - 6s - loss: 0.7200 - acc: 0.8000 - val_loss: 0.6153 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 20/80\n",
      "2/2 - 6s - loss: 0.6313 - acc: 0.7833 - val_loss: 0.5218 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/80\n",
      "2/2 - 6s - loss: 0.5096 - acc: 0.8000 - val_loss: 0.4921 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 22/80\n",
      "2/2 - 6s - loss: 0.4569 - acc: 0.7833 - val_loss: 0.4188 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/80\n",
      "2/2 - 6s - loss: 0.4177 - acc: 0.8000 - val_loss: 0.3880 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 24/80\n",
      "2/2 - 6s - loss: 0.3823 - acc: 0.8000 - val_loss: 0.3580 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/80\n",
      "2/2 - 5s - loss: 0.3545 - acc: 0.8000 - val_loss: 0.3621 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 26/80\n",
      "2/2 - 5s - loss: 0.3482 - acc: 0.8167 - val_loss: 0.3739 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 27/80\n",
      "2/2 - 6s - loss: 0.3526 - acc: 0.8167 - val_loss: 0.3438 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 28/80\n",
      "2/2 - 6s - loss: 0.3433 - acc: 0.8000 - val_loss: 0.3458 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 29/80\n",
      "2/2 - 6s - loss: 0.3198 - acc: 0.8333 - val_loss: 0.3272 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 30/80\n",
      "2/2 - 6s - loss: 0.3589 - acc: 0.8167 - val_loss: 0.3406 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 31/80\n",
      "2/2 - 6s - loss: 0.3712 - acc: 0.7833 - val_loss: 0.3386 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 32/80\n",
      "2/2 - 6s - loss: 0.3275 - acc: 0.8000 - val_loss: 0.5105 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 33/80\n",
      "2/2 - 6s - loss: 0.4820 - acc: 0.7333 - val_loss: 0.6119 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 34/80\n",
      "2/2 - 6s - loss: 0.5287 - acc: 0.7500 - val_loss: 0.3227 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 35/80\n",
      "2/2 - 6s - loss: 0.3987 - acc: 0.7833 - val_loss: 0.3677 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 36/80\n",
      "2/2 - 6s - loss: 0.4087 - acc: 0.8167 - val_loss: 0.3173 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 37/80\n",
      "2/2 - 6s - loss: 0.3561 - acc: 0.7833 - val_loss: 0.3338 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 38/80\n",
      "2/2 - 6s - loss: 0.3302 - acc: 0.8167 - val_loss: 0.3472 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 39/80\n",
      "2/2 - 6s - loss: 0.3598 - acc: 0.8000 - val_loss: 0.3321 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 40/80\n",
      "2/2 - 6s - loss: 0.3276 - acc: 0.8000 - val_loss: 0.3256 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 41/80\n",
      "2/2 - 6s - loss: 0.3138 - acc: 0.8500 - val_loss: 0.3847 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 42/80\n",
      "2/2 - 6s - loss: 0.4075 - acc: 0.7833 - val_loss: 0.3177 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 43/80\n",
      "2/2 - 6s - loss: 0.3525 - acc: 0.8000 - val_loss: 0.3588 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 44/80\n",
      "2/2 - 6s - loss: 0.3925 - acc: 0.7833 - val_loss: 0.3389 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 45/80\n",
      "2/2 - 6s - loss: 0.3328 - acc: 0.8167 - val_loss: 0.3270 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 46/80\n",
      "2/2 - 6s - loss: 0.3373 - acc: 0.8333 - val_loss: 0.3934 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 47/80\n",
      "2/2 - 6s - loss: 0.3891 - acc: 0.7667 - val_loss: 0.3227 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 48/80\n",
      "2/2 - 6s - loss: 0.3376 - acc: 0.8500 - val_loss: 0.3263 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 49/80\n",
      "2/2 - 6s - loss: 0.3404 - acc: 0.8167 - val_loss: 0.3308 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 50/80\n",
      "2/2 - 6s - loss: 0.3464 - acc: 0.8000 - val_loss: 0.3439 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 51/80\n",
      "2/2 - 6s - loss: 0.3546 - acc: 0.7833 - val_loss: 0.3408 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 52/80\n",
      "2/2 - 6s - loss: 0.3360 - acc: 0.8167 - val_loss: 0.3343 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 53/80\n",
      "2/2 - 6s - loss: 0.3254 - acc: 0.8667 - val_loss: 0.3336 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 54/80\n",
      "2/2 - 6s - loss: 0.3524 - acc: 0.7833 - val_loss: 0.3306 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 55/80\n",
      "2/2 - 6s - loss: 0.3325 - acc: 0.8333 - val_loss: 0.3334 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 56/80\n",
      "2/2 - 6s - loss: 0.3424 - acc: 0.8333 - val_loss: 0.3243 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 57/80\n",
      "2/2 - 6s - loss: 0.3207 - acc: 0.8500 - val_loss: 0.3242 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 58/80\n",
      "2/2 - 5s - loss: 0.3435 - acc: 0.8167 - val_loss: 0.3321 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 59/80\n",
      "2/2 - 6s - loss: 0.3453 - acc: 0.8167 - val_loss: 0.3272 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 60/80\n",
      "2/2 - 6s - loss: 0.3202 - acc: 0.8167 - val_loss: 0.3249 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 61/80\n",
      "2/2 - 6s - loss: 0.3230 - acc: 0.8167 - val_loss: 0.3167 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 62/80\n",
      "2/2 - 6s - loss: 0.3322 - acc: 0.8000 - val_loss: 0.3376 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 63/80\n",
      "2/2 - 6s - loss: 0.3385 - acc: 0.8167 - val_loss: 0.3231 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 64/80\n",
      "2/2 - 6s - loss: 0.3270 - acc: 0.8500 - val_loss: 0.3187 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 65/80\n",
      "2/2 - 6s - loss: 0.3389 - acc: 0.8000 - val_loss: 0.3299 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 66/80\n",
      "2/2 - 6s - loss: 0.3363 - acc: 0.8333 - val_loss: 0.3217 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 67/80\n",
      "2/2 - 6s - loss: 0.3390 - acc: 0.8333 - val_loss: 0.3145 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 68/80\n",
      "2/2 - 6s - loss: 0.3076 - acc: 0.8333 - val_loss: 0.3145 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 69/80\n",
      "2/2 - 6s - loss: 0.3252 - acc: 0.8500 - val_loss: 0.3260 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 70/80\n",
      "2/2 - 6s - loss: 0.3305 - acc: 0.8333 - val_loss: 0.3179 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 71/80\n",
      "2/2 - 6s - loss: 0.2975 - acc: 0.8500 - val_loss: 0.3097 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 72/80\n",
      "2/2 - 6s - loss: 0.3157 - acc: 0.8000 - val_loss: 0.3149 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 73/80\n",
      "2/2 - 6s - loss: 0.3311 - acc: 0.8000 - val_loss: 0.3023 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 74/80\n",
      "2/2 - 5s - loss: 0.3091 - acc: 0.8333 - val_loss: 0.3057 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 75/80\n",
      "2/2 - 6s - loss: 0.3027 - acc: 0.8500 - val_loss: 0.3156 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 76/80\n",
      "2/2 - 6s - loss: 0.3170 - acc: 0.8500 - val_loss: 0.3205 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 77/80\n",
      "2/2 - 6s - loss: 0.2962 - acc: 0.8167 - val_loss: 0.3080 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 78/80\n",
      "2/2 - 6s - loss: 0.3242 - acc: 0.8500 - val_loss: 0.3093 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 79/80\n",
      "2/2 - 6s - loss: 0.3238 - acc: 0.8500 - val_loss: 0.2989 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 80/80\n",
      "2/2 - 6s - loss: 0.3240 - acc: 0.8333 - val_loss: 0.3078 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 1/90\n",
      "2/2 - 8s - loss: 1.0986 - acc: 0.4167 - val_loss: 1.0970 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/90\n",
      "2/2 - 5s - loss: 1.0965 - acc: 0.4833 - val_loss: 1.0953 - val_acc: 0.4833 - 5s/epoch - 3s/step\n",
      "Epoch 3/90\n",
      "2/2 - 6s - loss: 1.0948 - acc: 0.4833 - val_loss: 1.0928 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/90\n",
      "2/2 - 6s - loss: 1.0931 - acc: 0.4833 - val_loss: 1.0896 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/90\n",
      "2/2 - 6s - loss: 1.0885 - acc: 0.4833 - val_loss: 1.0857 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 6/90\n",
      "2/2 - 6s - loss: 1.0850 - acc: 0.5333 - val_loss: 1.0801 - val_acc: 0.5667 - 6s/epoch - 3s/step\n",
      "Epoch 7/90\n",
      "2/2 - 6s - loss: 1.0799 - acc: 0.6500 - val_loss: 1.0734 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 8/90\n",
      "2/2 - 6s - loss: 1.0741 - acc: 0.7167 - val_loss: 1.0653 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 9/90\n",
      "2/2 - 6s - loss: 1.0682 - acc: 0.6833 - val_loss: 1.0599 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 10/90\n",
      "2/2 - 6s - loss: 1.0645 - acc: 0.6333 - val_loss: 1.0523 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 11/90\n",
      "2/2 - 6s - loss: 1.0531 - acc: 0.5333 - val_loss: 1.0451 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 12/90\n",
      "2/2 - 6s - loss: 1.0429 - acc: 0.5167 - val_loss: 1.0313 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 13/90\n",
      "2/2 - 6s - loss: 1.0309 - acc: 0.5333 - val_loss: 1.0111 - val_acc: 0.5667 - 6s/epoch - 3s/step\n",
      "Epoch 14/90\n",
      "2/2 - 6s - loss: 1.0183 - acc: 0.5833 - val_loss: 0.9860 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 15/90\n",
      "2/2 - 6s - loss: 0.9922 - acc: 0.6500 - val_loss: 0.9580 - val_acc: 0.6500 - 6s/epoch - 3s/step\n",
      "Epoch 16/90\n",
      "2/2 - 6s - loss: 0.9559 - acc: 0.6833 - val_loss: 0.9051 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 17/90\n",
      "2/2 - 6s - loss: 0.9028 - acc: 0.7667 - val_loss: 0.8378 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 18/90\n",
      "2/2 - 6s - loss: 0.8275 - acc: 0.7667 - val_loss: 0.7533 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 19/90\n",
      "2/2 - 6s - loss: 0.7538 - acc: 0.8000 - val_loss: 0.6603 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 20/90\n",
      "2/2 - 6s - loss: 0.6545 - acc: 0.7500 - val_loss: 0.5573 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 21/90\n",
      "2/2 - 6s - loss: 0.5521 - acc: 0.7833 - val_loss: 0.4923 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/90\n",
      "2/2 - 6s - loss: 0.4855 - acc: 0.8000 - val_loss: 0.4374 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/90\n",
      "2/2 - 6s - loss: 0.4399 - acc: 0.8000 - val_loss: 0.4029 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 24/90\n",
      "2/2 - 6s - loss: 0.4432 - acc: 0.8000 - val_loss: 0.3721 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/90\n",
      "2/2 - 6s - loss: 0.3769 - acc: 0.7833 - val_loss: 0.4962 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 26/90\n",
      "2/2 - 6s - loss: 0.4283 - acc: 0.7833 - val_loss: 0.3463 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 27/90\n",
      "2/2 - 6s - loss: 0.4529 - acc: 0.7500 - val_loss: 0.4640 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 28/90\n",
      "2/2 - 6s - loss: 0.3730 - acc: 0.8000 - val_loss: 0.3794 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 29/90\n",
      "2/2 - 6s - loss: 0.4118 - acc: 0.8000 - val_loss: 0.4393 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 30/90\n",
      "2/2 - 6s - loss: 0.4227 - acc: 0.7833 - val_loss: 0.3404 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 31/90\n",
      "2/2 - 6s - loss: 0.3770 - acc: 0.7833 - val_loss: 0.3765 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 32/90\n",
      "2/2 - 6s - loss: 0.3492 - acc: 0.8167 - val_loss: 0.3374 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/90\n",
      "2/2 - 6s - loss: 0.3406 - acc: 0.8333 - val_loss: 0.3560 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 34/90\n",
      "2/2 - 6s - loss: 0.3728 - acc: 0.8167 - val_loss: 0.3521 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 35/90\n",
      "2/2 - 6s - loss: 0.3410 - acc: 0.8167 - val_loss: 0.3286 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 36/90\n",
      "2/2 - 6s - loss: 0.3188 - acc: 0.8333 - val_loss: 0.3367 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/90\n",
      "2/2 - 6s - loss: 0.3292 - acc: 0.8167 - val_loss: 0.3393 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 38/90\n",
      "2/2 - 6s - loss: 0.3455 - acc: 0.8000 - val_loss: 0.3265 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 39/90\n",
      "2/2 - 6s - loss: 0.3357 - acc: 0.8167 - val_loss: 0.3224 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 40/90\n",
      "2/2 - 6s - loss: 0.3348 - acc: 0.8167 - val_loss: 0.3470 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 41/90\n",
      "2/2 - 6s - loss: 0.3157 - acc: 0.8667 - val_loss: 0.3259 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 42/90\n",
      "2/2 - 6s - loss: 0.3200 - acc: 0.8167 - val_loss: 0.3194 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 43/90\n",
      "2/2 - 5s - loss: 0.3335 - acc: 0.8167 - val_loss: 0.3362 - val_acc: 0.8000 - 5s/epoch - 3s/step\n",
      "Epoch 44/90\n",
      "2/2 - 6s - loss: 0.3258 - acc: 0.8167 - val_loss: 0.3368 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 45/90\n",
      "2/2 - 6s - loss: 0.3241 - acc: 0.8333 - val_loss: 0.3146 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 46/90\n",
      "2/2 - 6s - loss: 0.3105 - acc: 0.8333 - val_loss: 0.3095 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 47/90\n",
      "2/2 - 6s - loss: 0.3358 - acc: 0.8333 - val_loss: 0.3037 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 48/90\n",
      "2/2 - 6s - loss: 0.3184 - acc: 0.8500 - val_loss: 0.3196 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 49/90\n",
      "2/2 - 6s - loss: 0.3314 - acc: 0.8500 - val_loss: 0.3183 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 50/90\n",
      "2/2 - 6s - loss: 0.3225 - acc: 0.8667 - val_loss: 0.3194 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 51/90\n",
      "2/2 - 6s - loss: 0.3261 - acc: 0.8167 - val_loss: 0.3093 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 52/90\n",
      "2/2 - 6s - loss: 0.3058 - acc: 0.8500 - val_loss: 0.3154 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 53/90\n",
      "2/2 - 6s - loss: 0.3030 - acc: 0.8500 - val_loss: 0.3039 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 54/90\n",
      "2/2 - 6s - loss: 0.3202 - acc: 0.8333 - val_loss: 0.3157 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 55/90\n",
      "2/2 - 6s - loss: 0.3368 - acc: 0.8167 - val_loss: 0.3081 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 56/90\n",
      "2/2 - 6s - loss: 0.2954 - acc: 0.8833 - val_loss: 0.3041 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 57/90\n",
      "2/2 - 6s - loss: 0.2980 - acc: 0.8167 - val_loss: 0.3169 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 58/90\n",
      "2/2 - 6s - loss: 0.3026 - acc: 0.8500 - val_loss: 0.3241 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 59/90\n",
      "2/2 - 6s - loss: 0.3114 - acc: 0.8500 - val_loss: 0.3144 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 60/90\n",
      "2/2 - 6s - loss: 0.3071 - acc: 0.8667 - val_loss: 0.3220 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 61/90\n",
      "2/2 - 6s - loss: 0.3175 - acc: 0.8167 - val_loss: 0.3210 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 62/90\n",
      "2/2 - 6s - loss: 0.3206 - acc: 0.8167 - val_loss: 0.3428 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 63/90\n",
      "2/2 - 6s - loss: 0.3328 - acc: 0.8000 - val_loss: 0.2988 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 64/90\n",
      "2/2 - 6s - loss: 0.3328 - acc: 0.8333 - val_loss: 0.3669 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 65/90\n",
      "2/2 - 6s - loss: 0.3519 - acc: 0.7833 - val_loss: 0.3124 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 66/90\n",
      "2/2 - 6s - loss: 0.3583 - acc: 0.8167 - val_loss: 0.3112 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 67/90\n",
      "2/2 - 6s - loss: 0.3094 - acc: 0.8500 - val_loss: 0.3046 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 68/90\n",
      "2/2 - 6s - loss: 0.3213 - acc: 0.8167 - val_loss: 0.2978 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 69/90\n",
      "2/2 - 6s - loss: 0.2973 - acc: 0.8500 - val_loss: 0.2945 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 70/90\n",
      "2/2 - 6s - loss: 0.3457 - acc: 0.8500 - val_loss: 0.2998 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 71/90\n",
      "2/2 - 6s - loss: 0.3162 - acc: 0.8833 - val_loss: 0.2896 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 72/90\n",
      "2/2 - 6s - loss: 0.3001 - acc: 0.8500 - val_loss: 0.3060 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 73/90\n",
      "2/2 - 6s - loss: 0.2889 - acc: 0.8833 - val_loss: 0.3139 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 74/90\n",
      "2/2 - 6s - loss: 0.3017 - acc: 0.8000 - val_loss: 0.2926 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 75/90\n",
      "2/2 - 6s - loss: 0.3762 - acc: 0.7833 - val_loss: 0.2887 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 76/90\n",
      "2/2 - 6s - loss: 0.3103 - acc: 0.8333 - val_loss: 0.3189 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 77/90\n",
      "2/2 - 6s - loss: 0.3426 - acc: 0.8500 - val_loss: 0.3175 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 78/90\n",
      "2/2 - 6s - loss: 0.3141 - acc: 0.8500 - val_loss: 0.3042 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 79/90\n",
      "2/2 - 6s - loss: 0.2849 - acc: 0.8667 - val_loss: 0.3543 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 80/90\n",
      "2/2 - 6s - loss: 0.3179 - acc: 0.8333 - val_loss: 0.3004 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 81/90\n",
      "2/2 - 6s - loss: 0.3014 - acc: 0.8333 - val_loss: 0.3614 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 82/90\n",
      "2/2 - 6s - loss: 0.3687 - acc: 0.8000 - val_loss: 0.2868 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 83/90\n",
      "2/2 - 6s - loss: 0.2947 - acc: 0.8500 - val_loss: 0.3569 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 84/90\n",
      "2/2 - 6s - loss: 0.3559 - acc: 0.8167 - val_loss: 0.2995 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 85/90\n",
      "2/2 - 6s - loss: 0.3036 - acc: 0.8500 - val_loss: 0.3194 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 86/90\n",
      "2/2 - 6s - loss: 0.3513 - acc: 0.7833 - val_loss: 0.2972 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 87/90\n",
      "2/2 - 6s - loss: 0.2876 - acc: 0.8500 - val_loss: 0.2885 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 88/90\n",
      "2/2 - 6s - loss: 0.3296 - acc: 0.8000 - val_loss: 0.3167 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 89/90\n",
      "2/2 - 6s - loss: 0.3214 - acc: 0.8333 - val_loss: 0.3039 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 90/90\n",
      "2/2 - 6s - loss: 0.3043 - acc: 0.8667 - val_loss: 0.3196 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 1/100\n",
      "2/2 - 8s - loss: 1.0983 - acc: 0.4500 - val_loss: 1.0967 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "2/2 - 6s - loss: 1.0964 - acc: 0.4833 - val_loss: 1.0945 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/100\n",
      "2/2 - 6s - loss: 1.0944 - acc: 0.4833 - val_loss: 1.0917 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/100\n",
      "2/2 - 6s - loss: 1.0922 - acc: 0.4833 - val_loss: 1.0881 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/100\n",
      "2/2 - 6s - loss: 1.0864 - acc: 0.6167 - val_loss: 1.0838 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 6/100\n",
      "2/2 - 6s - loss: 1.0833 - acc: 0.6500 - val_loss: 1.0778 - val_acc: 0.7167 - 6s/epoch - 3s/step\n",
      "Epoch 7/100\n",
      "2/2 - 6s - loss: 1.0788 - acc: 0.5833 - val_loss: 1.0712 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 8/100\n",
      "2/2 - 6s - loss: 1.0736 - acc: 0.6500 - val_loss: 1.0645 - val_acc: 0.7167 - 6s/epoch - 3s/step\n",
      "Epoch 9/100\n",
      "2/2 - 6s - loss: 1.0632 - acc: 0.6833 - val_loss: 1.0563 - val_acc: 0.5500 - 6s/epoch - 3s/step\n",
      "Epoch 10/100\n",
      "2/2 - 6s - loss: 1.0596 - acc: 0.6167 - val_loss: 1.0522 - val_acc: 0.5667 - 6s/epoch - 3s/step\n",
      "Epoch 11/100\n",
      "2/2 - 5s - loss: 1.0548 - acc: 0.6333 - val_loss: 1.0425 - val_acc: 0.6333 - 5s/epoch - 3s/step\n",
      "Epoch 12/100\n",
      "2/2 - 6s - loss: 1.0449 - acc: 0.5500 - val_loss: 1.0305 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 13/100\n",
      "2/2 - 6s - loss: 1.0328 - acc: 0.4833 - val_loss: 1.0102 - val_acc: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 14/100\n",
      "2/2 - 5s - loss: 1.0159 - acc: 0.7167 - val_loss: 0.9921 - val_acc: 0.7667 - 5s/epoch - 3s/step\n",
      "Epoch 15/100\n",
      "2/2 - 6s - loss: 0.9925 - acc: 0.7500 - val_loss: 0.9578 - val_acc: 0.6167 - 6s/epoch - 3s/step\n",
      "Epoch 16/100\n",
      "2/2 - 6s - loss: 0.9586 - acc: 0.6167 - val_loss: 0.9037 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 17/100\n",
      "2/2 - 6s - loss: 0.8999 - acc: 0.7500 - val_loss: 0.8313 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 18/100\n",
      "2/2 - 6s - loss: 0.8247 - acc: 0.7500 - val_loss: 0.7385 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 19/100\n",
      "2/2 - 6s - loss: 0.7326 - acc: 0.7833 - val_loss: 0.6342 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 20/100\n",
      "2/2 - 6s - loss: 0.6341 - acc: 0.8000 - val_loss: 0.5449 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 21/100\n",
      "2/2 - 6s - loss: 0.5703 - acc: 0.7833 - val_loss: 0.4723 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/100\n",
      "2/2 - 6s - loss: 0.5271 - acc: 0.7833 - val_loss: 0.4360 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/100\n",
      "2/2 - 6s - loss: 0.4281 - acc: 0.8000 - val_loss: 0.5135 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 24/100\n",
      "2/2 - 6s - loss: 0.4778 - acc: 0.7667 - val_loss: 0.3810 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/100\n",
      "2/2 - 6s - loss: 0.4319 - acc: 0.8000 - val_loss: 0.4053 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 26/100\n",
      "2/2 - 6s - loss: 0.3775 - acc: 0.8167 - val_loss: 0.5139 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 27/100\n",
      "2/2 - 6s - loss: 0.5149 - acc: 0.7500 - val_loss: 0.3895 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 28/100\n",
      "2/2 - 6s - loss: 0.3852 - acc: 0.8167 - val_loss: 0.5609 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 29/100\n",
      "2/2 - 6s - loss: 0.5077 - acc: 0.7167 - val_loss: 0.3415 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 30/100\n",
      "2/2 - 6s - loss: 0.3729 - acc: 0.8000 - val_loss: 0.4394 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 31/100\n",
      "2/2 - 6s - loss: 0.4339 - acc: 0.8000 - val_loss: 0.3557 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 32/100\n",
      "2/2 - 6s - loss: 0.3645 - acc: 0.8000 - val_loss: 0.3464 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/100\n",
      "2/2 - 6s - loss: 0.3739 - acc: 0.8000 - val_loss: 0.3619 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 34/100\n",
      "2/2 - 6s - loss: 0.3749 - acc: 0.8000 - val_loss: 0.3461 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 35/100\n",
      "2/2 - 6s - loss: 0.3184 - acc: 0.8167 - val_loss: 0.3485 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 36/100\n",
      "2/2 - 6s - loss: 0.4171 - acc: 0.8167 - val_loss: 0.3700 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/100\n",
      "2/2 - 6s - loss: 0.3374 - acc: 0.8333 - val_loss: 0.3303 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 38/100\n",
      "2/2 - 6s - loss: 0.3393 - acc: 0.8167 - val_loss: 0.3705 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 39/100\n",
      "2/2 - 6s - loss: 0.3823 - acc: 0.8000 - val_loss: 0.3326 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 40/100\n",
      "2/2 - 6s - loss: 0.3171 - acc: 0.8333 - val_loss: 0.3407 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 41/100\n",
      "2/2 - 6s - loss: 0.3396 - acc: 0.8333 - val_loss: 0.3476 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 42/100\n",
      "2/2 - 6s - loss: 0.3277 - acc: 0.8333 - val_loss: 0.3389 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 43/100\n",
      "2/2 - 6s - loss: 0.3394 - acc: 0.8000 - val_loss: 0.3195 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 44/100\n",
      "2/2 - 6s - loss: 0.3439 - acc: 0.8167 - val_loss: 0.3396 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 45/100\n",
      "2/2 - 5s - loss: 0.3525 - acc: 0.8000 - val_loss: 0.3416 - val_acc: 0.8167 - 5s/epoch - 3s/step\n",
      "Epoch 46/100\n",
      "2/2 - 6s - loss: 0.3354 - acc: 0.8333 - val_loss: 0.3268 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 47/100\n",
      "2/2 - 6s - loss: 0.3189 - acc: 0.8333 - val_loss: 0.3512 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 48/100\n",
      "2/2 - 5s - loss: 0.3306 - acc: 0.8333 - val_loss: 0.3164 - val_acc: 0.8667 - 5s/epoch - 3s/step\n",
      "Epoch 49/100\n",
      "2/2 - 6s - loss: 0.3460 - acc: 0.7833 - val_loss: 0.3115 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 50/100\n",
      "2/2 - 6s - loss: 0.3309 - acc: 0.8167 - val_loss: 0.3226 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 51/100\n",
      "2/2 - 6s - loss: 0.3259 - acc: 0.8667 - val_loss: 0.3241 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 52/100\n",
      "2/2 - 5s - loss: 0.3182 - acc: 0.8167 - val_loss: 0.3088 - val_acc: 0.8500 - 5s/epoch - 3s/step\n",
      "Epoch 53/100\n",
      "2/2 - 6s - loss: 0.3235 - acc: 0.8333 - val_loss: 0.2982 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 54/100\n",
      "2/2 - 6s - loss: 0.3414 - acc: 0.8333 - val_loss: 0.3196 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 55/100\n",
      "2/2 - 6s - loss: 0.3233 - acc: 0.8667 - val_loss: 0.3067 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 56/100\n",
      "2/2 - 6s - loss: 0.3081 - acc: 0.8000 - val_loss: 0.3116 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 57/100\n",
      "2/2 - 6s - loss: 0.3371 - acc: 0.8167 - val_loss: 0.3170 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 58/100\n",
      "2/2 - 6s - loss: 0.3222 - acc: 0.8667 - val_loss: 0.3296 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 59/100\n",
      "2/2 - 6s - loss: 0.3237 - acc: 0.8333 - val_loss: 0.3094 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 60/100\n",
      "2/2 - 6s - loss: 0.3379 - acc: 0.8333 - val_loss: 0.3159 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 61/100\n",
      "2/2 - 6s - loss: 0.3291 - acc: 0.8000 - val_loss: 0.3037 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 62/100\n",
      "2/2 - 6s - loss: 0.2937 - acc: 0.8500 - val_loss: 0.3165 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 63/100\n",
      "2/2 - 6s - loss: 0.3092 - acc: 0.8167 - val_loss: 0.3177 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 64/100\n",
      "2/2 - 6s - loss: 0.3021 - acc: 0.8500 - val_loss: 0.3130 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 65/100\n",
      "2/2 - 6s - loss: 0.3034 - acc: 0.8500 - val_loss: 0.3049 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 66/100\n",
      "2/2 - 6s - loss: 0.3313 - acc: 0.8333 - val_loss: 0.3078 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 67/100\n",
      "2/2 - 6s - loss: 0.3281 - acc: 0.8333 - val_loss: 0.3028 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 68/100\n",
      "2/2 - 6s - loss: 0.3059 - acc: 0.8333 - val_loss: 0.3093 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 69/100\n",
      "2/2 - 6s - loss: 0.3069 - acc: 0.8333 - val_loss: 0.3155 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 70/100\n",
      "2/2 - 6s - loss: 0.2939 - acc: 0.8167 - val_loss: 0.3121 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 71/100\n",
      "2/2 - 6s - loss: 0.3479 - acc: 0.7833 - val_loss: 0.3033 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 72/100\n",
      "2/2 - 6s - loss: 0.3623 - acc: 0.8000 - val_loss: 0.3194 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 73/100\n",
      "2/2 - 6s - loss: 0.2965 - acc: 0.8167 - val_loss: 0.3058 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 74/100\n",
      "2/2 - 6s - loss: 0.3033 - acc: 0.8333 - val_loss: 0.3366 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 75/100\n",
      "2/2 - 5s - loss: 0.3093 - acc: 0.8333 - val_loss: 0.3056 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 76/100\n",
      "2/2 - 6s - loss: 0.3198 - acc: 0.8000 - val_loss: 0.2964 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 77/100\n",
      "2/2 - 6s - loss: 0.3149 - acc: 0.8167 - val_loss: 0.3086 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 78/100\n",
      "2/2 - 6s - loss: 0.2978 - acc: 0.8500 - val_loss: 0.3173 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 79/100\n",
      "2/2 - 6s - loss: 0.3193 - acc: 0.9000 - val_loss: 0.3114 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 80/100\n",
      "2/2 - 6s - loss: 0.3076 - acc: 0.8667 - val_loss: 0.3220 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 81/100\n",
      "2/2 - 6s - loss: 0.3102 - acc: 0.8667 - val_loss: 0.3182 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 82/100\n",
      "2/2 - 6s - loss: 0.3109 - acc: 0.8333 - val_loss: 0.3034 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 83/100\n",
      "2/2 - 6s - loss: 0.2770 - acc: 0.8667 - val_loss: 0.3123 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 84/100\n",
      "2/2 - 6s - loss: 0.3311 - acc: 0.8167 - val_loss: 0.2973 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 85/100\n",
      "2/2 - 5s - loss: 0.3145 - acc: 0.8333 - val_loss: 0.3102 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 86/100\n",
      "2/2 - 6s - loss: 0.3414 - acc: 0.8167 - val_loss: 0.3043 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 87/100\n",
      "2/2 - 6s - loss: 0.2833 - acc: 0.9000 - val_loss: 0.2969 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 88/100\n",
      "2/2 - 6s - loss: 0.3280 - acc: 0.8333 - val_loss: 0.2870 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 89/100\n",
      "2/2 - 6s - loss: 0.3011 - acc: 0.8667 - val_loss: 0.2795 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 90/100\n",
      "2/2 - 6s - loss: 0.3348 - acc: 0.7833 - val_loss: 0.2853 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 91/100\n",
      "2/2 - 6s - loss: 0.3069 - acc: 0.8667 - val_loss: 0.2951 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 92/100\n",
      "2/2 - 6s - loss: 0.3069 - acc: 0.8167 - val_loss: 0.3149 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 93/100\n",
      "2/2 - 6s - loss: 0.3091 - acc: 0.8333 - val_loss: 0.2967 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 94/100\n",
      "2/2 - 6s - loss: 0.3102 - acc: 0.8500 - val_loss: 0.3182 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 95/100\n",
      "2/2 - 5s - loss: 0.3339 - acc: 0.8333 - val_loss: 0.2789 - val_acc: 0.8667 - 5s/epoch - 3s/step\n",
      "Epoch 96/100\n",
      "2/2 - 6s - loss: 0.3058 - acc: 0.8333 - val_loss: 0.3015 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 97/100\n",
      "2/2 - 6s - loss: 0.3162 - acc: 0.8167 - val_loss: 0.2990 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 98/100\n",
      "2/2 - 6s - loss: 0.2778 - acc: 0.8833 - val_loss: 0.2954 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 99/100\n",
      "2/2 - 5s - loss: 0.3126 - acc: 0.8000 - val_loss: 0.2856 - val_acc: 0.8167 - 5s/epoch - 3s/step\n",
      "Epoch 100/100\n",
      "2/2 - 6s - loss: 0.2928 - acc: 0.8333 - val_loss: 0.2971 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 1/110\n",
      "2/2 - 8s - loss: 1.0982 - acc: 0.5167 - val_loss: 1.0969 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/110\n",
      "2/2 - 5s - loss: 1.0965 - acc: 0.5167 - val_loss: 1.0948 - val_acc: 0.4833 - 5s/epoch - 3s/step\n",
      "Epoch 3/110\n",
      "2/2 - 6s - loss: 1.0950 - acc: 0.4833 - val_loss: 1.0919 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/110\n",
      "2/2 - 6s - loss: 1.0912 - acc: 0.4833 - val_loss: 1.0885 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/110\n",
      "2/2 - 6s - loss: 1.0892 - acc: 0.6167 - val_loss: 1.0837 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 6/110\n",
      "2/2 - 6s - loss: 1.0825 - acc: 0.7833 - val_loss: 1.0782 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 7/110\n",
      "2/2 - 6s - loss: 1.0781 - acc: 0.7167 - val_loss: 1.0715 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 8/110\n",
      "2/2 - 6s - loss: 1.0706 - acc: 0.6000 - val_loss: 1.0649 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 9/110\n",
      "2/2 - 6s - loss: 1.0680 - acc: 0.5167 - val_loss: 1.0603 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 10/110\n",
      "2/2 - 6s - loss: 1.0582 - acc: 0.6333 - val_loss: 1.0559 - val_acc: 0.5167 - 6s/epoch - 3s/step\n",
      "Epoch 11/110\n",
      "2/2 - 6s - loss: 1.0519 - acc: 0.5833 - val_loss: 1.0495 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 12/110\n",
      "2/2 - 6s - loss: 1.0523 - acc: 0.5833 - val_loss: 1.0385 - val_acc: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 13/110\n",
      "2/2 - 6s - loss: 1.0385 - acc: 0.5333 - val_loss: 1.0264 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 14/110\n",
      "2/2 - 6s - loss: 1.0253 - acc: 0.4833 - val_loss: 1.0059 - val_acc: 0.5333 - 6s/epoch - 3s/step\n",
      "Epoch 15/110\n",
      "2/2 - 6s - loss: 1.0020 - acc: 0.5500 - val_loss: 0.9776 - val_acc: 0.6167 - 6s/epoch - 3s/step\n",
      "Epoch 16/110\n",
      "2/2 - 6s - loss: 0.9791 - acc: 0.5333 - val_loss: 0.9372 - val_acc: 0.7000 - 6s/epoch - 3s/step\n",
      "Epoch 17/110\n",
      "2/2 - 5s - loss: 0.9396 - acc: 0.7500 - val_loss: 0.8858 - val_acc: 0.7500 - 5s/epoch - 3s/step\n",
      "Epoch 18/110\n",
      "2/2 - 6s - loss: 0.8822 - acc: 0.7333 - val_loss: 0.8400 - val_acc: 0.6667 - 6s/epoch - 3s/step\n",
      "Epoch 19/110\n",
      "2/2 - 6s - loss: 0.8310 - acc: 0.6833 - val_loss: 0.7228 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/110\n",
      "2/2 - 6s - loss: 0.7179 - acc: 0.8000 - val_loss: 0.6170 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 21/110\n",
      "2/2 - 6s - loss: 0.6402 - acc: 0.7500 - val_loss: 0.5206 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 22/110\n",
      "2/2 - 6s - loss: 0.5341 - acc: 0.8000 - val_loss: 0.4632 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 23/110\n",
      "2/2 - 6s - loss: 0.4560 - acc: 0.8000 - val_loss: 0.4547 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 24/110\n",
      "2/2 - 6s - loss: 0.4633 - acc: 0.8000 - val_loss: 0.4091 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/110\n",
      "2/2 - 6s - loss: 0.6189 - acc: 0.6833 - val_loss: 0.3588 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 26/110\n",
      "2/2 - 6s - loss: 0.5431 - acc: 0.7833 - val_loss: 0.5040 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 27/110\n",
      "2/2 - 5s - loss: 0.5173 - acc: 0.7667 - val_loss: 0.3563 - val_acc: 0.8167 - 5s/epoch - 3s/step\n",
      "Epoch 28/110\n",
      "2/2 - 6s - loss: 0.4132 - acc: 0.7667 - val_loss: 0.5280 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 29/110\n",
      "2/2 - 6s - loss: 0.4786 - acc: 0.7333 - val_loss: 0.3388 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 30/110\n",
      "2/2 - 6s - loss: 0.3699 - acc: 0.8500 - val_loss: 0.4019 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 31/110\n",
      "2/2 - 5s - loss: 0.4297 - acc: 0.8000 - val_loss: 0.3852 - val_acc: 0.8167 - 5s/epoch - 3s/step\n",
      "Epoch 32/110\n",
      "2/2 - 6s - loss: 0.3838 - acc: 0.8167 - val_loss: 0.3477 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/110\n",
      "2/2 - 6s - loss: 0.3680 - acc: 0.8167 - val_loss: 0.4061 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 34/110\n",
      "2/2 - 6s - loss: 0.3674 - acc: 0.8167 - val_loss: 0.3511 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 35/110\n",
      "2/2 - 6s - loss: 0.3460 - acc: 0.8167 - val_loss: 0.3660 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 36/110\n",
      "2/2 - 6s - loss: 0.3558 - acc: 0.8167 - val_loss: 0.3709 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/110\n",
      "2/2 - 6s - loss: 0.3604 - acc: 0.8167 - val_loss: 0.3330 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 38/110\n",
      "2/2 - 6s - loss: 0.3343 - acc: 0.8000 - val_loss: 0.3325 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 39/110\n",
      "2/2 - 6s - loss: 0.3303 - acc: 0.8167 - val_loss: 0.3785 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 40/110\n",
      "2/2 - 6s - loss: 0.3529 - acc: 0.8167 - val_loss: 0.3415 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 41/110\n",
      "2/2 - 6s - loss: 0.3266 - acc: 0.8167 - val_loss: 0.3283 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 42/110\n",
      "2/2 - 6s - loss: 0.3166 - acc: 0.8167 - val_loss: 0.3226 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 43/110\n",
      "2/2 - 6s - loss: 0.3498 - acc: 0.8000 - val_loss: 0.3387 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 44/110\n",
      "2/2 - 6s - loss: 0.3483 - acc: 0.8167 - val_loss: 0.3137 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 45/110\n",
      "2/2 - 6s - loss: 0.3260 - acc: 0.8500 - val_loss: 0.3201 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 46/110\n",
      "2/2 - 6s - loss: 0.3096 - acc: 0.8500 - val_loss: 0.3312 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 47/110\n",
      "2/2 - 5s - loss: 0.3290 - acc: 0.8167 - val_loss: 0.3316 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 48/110\n",
      "2/2 - 6s - loss: 0.3407 - acc: 0.8333 - val_loss: 0.3203 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 49/110\n",
      "2/2 - 6s - loss: 0.3055 - acc: 0.8500 - val_loss: 0.3202 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 50/110\n",
      "2/2 - 6s - loss: 0.3473 - acc: 0.8333 - val_loss: 0.3337 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 51/110\n",
      "2/2 - 5s - loss: 0.3477 - acc: 0.8000 - val_loss: 0.3143 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 52/110\n",
      "2/2 - 6s - loss: 0.3285 - acc: 0.8333 - val_loss: 0.3500 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 53/110\n",
      "2/2 - 6s - loss: 0.3377 - acc: 0.8000 - val_loss: 0.3175 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 54/110\n",
      "2/2 - 6s - loss: 0.3264 - acc: 0.8333 - val_loss: 0.3410 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 55/110\n",
      "2/2 - 5s - loss: 0.3316 - acc: 0.8000 - val_loss: 0.3446 - val_acc: 0.8333 - 5s/epoch - 3s/step\n",
      "Epoch 56/110\n",
      "2/2 - 6s - loss: 0.3597 - acc: 0.7833 - val_loss: 0.3020 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 57/110\n",
      "2/2 - 6s - loss: 0.3162 - acc: 0.8333 - val_loss: 0.3333 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 58/110\n",
      "2/2 - 6s - loss: 0.3372 - acc: 0.8167 - val_loss: 0.3144 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 59/110\n",
      "2/2 - 6s - loss: 0.3146 - acc: 0.8333 - val_loss: 0.3261 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 60/110\n",
      "2/2 - 6s - loss: 0.3432 - acc: 0.7333 - val_loss: 0.3085 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 61/110\n",
      "2/2 - 6s - loss: 0.3300 - acc: 0.8000 - val_loss: 0.3260 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 62/110\n",
      "2/2 - 6s - loss: 0.3230 - acc: 0.8000 - val_loss: 0.3007 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 63/110\n",
      "2/2 - 6s - loss: 0.3019 - acc: 0.8667 - val_loss: 0.3100 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 64/110\n",
      "2/2 - 6s - loss: 0.2877 - acc: 0.8667 - val_loss: 0.3082 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 65/110\n",
      "2/2 - 6s - loss: 0.3217 - acc: 0.8500 - val_loss: 0.3430 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 66/110\n",
      "2/2 - 6s - loss: 0.3167 - acc: 0.8667 - val_loss: 0.3308 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 67/110\n",
      "2/2 - 6s - loss: 0.2952 - acc: 0.8500 - val_loss: 0.3160 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 68/110\n",
      "2/2 - 6s - loss: 0.3191 - acc: 0.8500 - val_loss: 0.3229 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 69/110\n",
      "2/2 - 6s - loss: 0.3495 - acc: 0.8000 - val_loss: 0.3209 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 70/110\n",
      "2/2 - 6s - loss: 0.3079 - acc: 0.8333 - val_loss: 0.2967 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 71/110\n",
      "2/2 - 6s - loss: 0.3169 - acc: 0.8000 - val_loss: 0.3074 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 72/110\n",
      "2/2 - 6s - loss: 0.3658 - acc: 0.7667 - val_loss: 0.3018 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 73/110\n",
      "2/2 - 6s - loss: 0.2986 - acc: 0.8333 - val_loss: 0.3127 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 74/110\n",
      "2/2 - 6s - loss: 0.3121 - acc: 0.8667 - val_loss: 0.3179 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 75/110\n",
      "2/2 - 6s - loss: 0.3189 - acc: 0.8500 - val_loss: 0.3039 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 76/110\n",
      "2/2 - 5s - loss: 0.3020 - acc: 0.8000 - val_loss: 0.3013 - val_acc: 0.8500 - 5s/epoch - 3s/step\n",
      "Epoch 77/110\n",
      "2/2 - 6s - loss: 0.2933 - acc: 0.8500 - val_loss: 0.3314 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 78/110\n",
      "2/2 - 6s - loss: 0.3114 - acc: 0.8167 - val_loss: 0.3155 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 79/110\n",
      "2/2 - 6s - loss: 0.3080 - acc: 0.8500 - val_loss: 0.2962 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 80/110\n",
      "2/2 - 6s - loss: 0.3183 - acc: 0.8333 - val_loss: 0.2989 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 81/110\n",
      "2/2 - 6s - loss: 0.3343 - acc: 0.8333 - val_loss: 0.3036 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 82/110\n",
      "2/2 - 6s - loss: 0.2978 - acc: 0.8333 - val_loss: 0.3032 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 83/110\n",
      "2/2 - 6s - loss: 0.3006 - acc: 0.8833 - val_loss: 0.3023 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 84/110\n",
      "2/2 - 6s - loss: 0.2855 - acc: 0.8500 - val_loss: 0.3032 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 85/110\n",
      "2/2 - 6s - loss: 0.2817 - acc: 0.8500 - val_loss: 0.2947 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 86/110\n",
      "2/2 - 6s - loss: 0.3010 - acc: 0.8167 - val_loss: 0.2878 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 87/110\n",
      "2/2 - 6s - loss: 0.3042 - acc: 0.7833 - val_loss: 0.2925 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 88/110\n",
      "2/2 - 6s - loss: 0.3095 - acc: 0.8667 - val_loss: 0.2913 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 89/110\n",
      "2/2 - 6s - loss: 0.2848 - acc: 0.8333 - val_loss: 0.2984 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 90/110\n",
      "2/2 - 6s - loss: 0.3224 - acc: 0.8333 - val_loss: 0.3112 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 91/110\n",
      "2/2 - 6s - loss: 0.2919 - acc: 0.8500 - val_loss: 0.2912 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 92/110\n",
      "2/2 - 6s - loss: 0.3090 - acc: 0.8333 - val_loss: 0.2827 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 93/110\n",
      "2/2 - 6s - loss: 0.3001 - acc: 0.8333 - val_loss: 0.2953 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 94/110\n",
      "2/2 - 6s - loss: 0.3122 - acc: 0.8667 - val_loss: 0.3046 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 95/110\n",
      "2/2 - 6s - loss: 0.2966 - acc: 0.8167 - val_loss: 0.2912 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 96/110\n",
      "2/2 - 6s - loss: 0.3489 - acc: 0.7833 - val_loss: 0.3118 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 97/110\n",
      "2/2 - 6s - loss: 0.3046 - acc: 0.8333 - val_loss: 0.2977 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 98/110\n",
      "2/2 - 6s - loss: 0.3003 - acc: 0.8333 - val_loss: 0.3885 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 99/110\n",
      "2/2 - 6s - loss: 0.3966 - acc: 0.8500 - val_loss: 0.2963 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 100/110\n",
      "2/2 - 6s - loss: 0.3017 - acc: 0.8667 - val_loss: 0.6347 - val_acc: 0.6833 - 6s/epoch - 3s/step\n",
      "Epoch 101/110\n",
      "2/2 - 6s - loss: 0.5365 - acc: 0.7833 - val_loss: 0.4247 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 102/110\n",
      "2/2 - 6s - loss: 0.5582 - acc: 0.8000 - val_loss: 0.4010 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 103/110\n",
      "2/2 - 6s - loss: 0.4116 - acc: 0.8167 - val_loss: 0.3253 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 104/110\n",
      "2/2 - 6s - loss: 0.3798 - acc: 0.8333 - val_loss: 0.4260 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 105/110\n",
      "2/2 - 6s - loss: 0.3656 - acc: 0.8000 - val_loss: 0.3181 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 106/110\n",
      "2/2 - 6s - loss: 0.3323 - acc: 0.8167 - val_loss: 0.3368 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 107/110\n",
      "2/2 - 6s - loss: 0.3459 - acc: 0.8000 - val_loss: 0.3157 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 108/110\n",
      "2/2 - 6s - loss: 0.3210 - acc: 0.8667 - val_loss: 0.3053 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 109/110\n",
      "2/2 - 6s - loss: 0.3203 - acc: 0.8500 - val_loss: 0.3260 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 110/110\n",
      "2/2 - 6s - loss: 0.3229 - acc: 0.8333 - val_loss: 0.3233 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 1/120\n",
      "2/2 - 8s - loss: 1.0985 - acc: 0.4000 - val_loss: 1.0967 - val_acc: 0.4833 - 8s/epoch - 4s/step\n",
      "Epoch 2/120\n",
      "2/2 - 6s - loss: 1.0964 - acc: 0.4833 - val_loss: 1.0947 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 3/120\n",
      "2/2 - 6s - loss: 1.0945 - acc: 0.4833 - val_loss: 1.0921 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 4/120\n",
      "2/2 - 6s - loss: 1.0914 - acc: 0.4833 - val_loss: 1.0884 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 5/120\n",
      "2/2 - 6s - loss: 1.0890 - acc: 0.5167 - val_loss: 1.0834 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 6/120\n",
      "2/2 - 6s - loss: 1.0836 - acc: 0.5333 - val_loss: 1.0768 - val_acc: 0.5833 - 6s/epoch - 3s/step\n",
      "Epoch 7/120\n",
      "2/2 - 6s - loss: 1.0746 - acc: 0.6500 - val_loss: 1.0697 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 8/120\n",
      "2/2 - 6s - loss: 1.0715 - acc: 0.6500 - val_loss: 1.0619 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 9/120\n",
      "2/2 - 6s - loss: 1.0620 - acc: 0.6833 - val_loss: 1.0572 - val_acc: 0.5667 - 6s/epoch - 3s/step\n",
      "Epoch 10/120\n",
      "2/2 - 6s - loss: 1.0621 - acc: 0.5333 - val_loss: 1.0511 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 11/120\n",
      "2/2 - 6s - loss: 1.0520 - acc: 0.4833 - val_loss: 1.0431 - val_acc: 0.4833 - 6s/epoch - 3s/step\n",
      "Epoch 12/120\n",
      "2/2 - 6s - loss: 1.0405 - acc: 0.5000 - val_loss: 1.0322 - val_acc: 0.5167 - 6s/epoch - 3s/step\n",
      "Epoch 13/120\n",
      "2/2 - 6s - loss: 1.0303 - acc: 0.5500 - val_loss: 1.0157 - val_acc: 0.5167 - 6s/epoch - 3s/step\n",
      "Epoch 14/120\n",
      "2/2 - 6s - loss: 1.0082 - acc: 0.5833 - val_loss: 0.9879 - val_acc: 0.6333 - 6s/epoch - 3s/step\n",
      "Epoch 15/120\n",
      "2/2 - 5s - loss: 0.9867 - acc: 0.6667 - val_loss: 0.9504 - val_acc: 0.6667 - 5s/epoch - 3s/step\n",
      "Epoch 16/120\n",
      "2/2 - 6s - loss: 0.9496 - acc: 0.6833 - val_loss: 0.8983 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 17/120\n",
      "2/2 - 6s - loss: 0.8972 - acc: 0.7500 - val_loss: 0.8218 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 18/120\n",
      "2/2 - 6s - loss: 0.8096 - acc: 0.7833 - val_loss: 0.7282 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 19/120\n",
      "2/2 - 6s - loss: 0.7095 - acc: 0.7500 - val_loss: 0.6226 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 20/120\n",
      "2/2 - 6s - loss: 0.6062 - acc: 0.7833 - val_loss: 0.5352 - val_acc: 0.7667 - 6s/epoch - 3s/step\n",
      "Epoch 21/120\n",
      "2/2 - 6s - loss: 0.5057 - acc: 0.8000 - val_loss: 0.5355 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 22/120\n",
      "2/2 - 6s - loss: 0.5117 - acc: 0.7833 - val_loss: 0.5658 - val_acc: 0.7500 - 6s/epoch - 3s/step\n",
      "Epoch 23/120\n",
      "2/2 - 6s - loss: 0.5024 - acc: 0.7667 - val_loss: 0.3992 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 24/120\n",
      "2/2 - 6s - loss: 0.4385 - acc: 0.8000 - val_loss: 0.3771 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 25/120\n",
      "2/2 - 6s - loss: 0.3831 - acc: 0.8167 - val_loss: 0.3898 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 26/120\n",
      "2/2 - 6s - loss: 0.3922 - acc: 0.7833 - val_loss: 0.3375 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 27/120\n",
      "2/2 - 6s - loss: 0.3457 - acc: 0.8167 - val_loss: 0.3590 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 28/120\n",
      "2/2 - 6s - loss: 0.3814 - acc: 0.8000 - val_loss: 0.3380 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 29/120\n",
      "2/2 - 6s - loss: 0.3337 - acc: 0.8500 - val_loss: 0.3823 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 30/120\n",
      "2/2 - 6s - loss: 0.3781 - acc: 0.8167 - val_loss: 0.3202 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 31/120\n",
      "2/2 - 6s - loss: 0.3316 - acc: 0.8167 - val_loss: 0.3365 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 32/120\n",
      "2/2 - 6s - loss: 0.3523 - acc: 0.8167 - val_loss: 0.3390 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 33/120\n",
      "2/2 - 6s - loss: 0.3248 - acc: 0.8167 - val_loss: 0.3144 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 34/120\n",
      "2/2 - 6s - loss: 0.3348 - acc: 0.8167 - val_loss: 0.3164 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 35/120\n",
      "2/2 - 6s - loss: 0.3459 - acc: 0.8333 - val_loss: 0.3264 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 36/120\n",
      "2/2 - 6s - loss: 0.3102 - acc: 0.8500 - val_loss: 0.3278 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 37/120\n",
      "2/2 - 6s - loss: 0.3173 - acc: 0.8500 - val_loss: 0.3229 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 38/120\n",
      "2/2 - 6s - loss: 0.3285 - acc: 0.8333 - val_loss: 0.3130 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 39/120\n",
      "2/2 - 6s - loss: 0.3064 - acc: 0.9000 - val_loss: 0.3209 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 40/120\n",
      "2/2 - 6s - loss: 0.3308 - acc: 0.8500 - val_loss: 0.3329 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 41/120\n",
      "2/2 - 6s - loss: 0.3227 - acc: 0.8333 - val_loss: 0.3300 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 42/120\n",
      "2/2 - 6s - loss: 0.3206 - acc: 0.8667 - val_loss: 0.3260 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 43/120\n",
      "2/2 - 6s - loss: 0.3578 - acc: 0.7833 - val_loss: 0.3470 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 44/120\n",
      "2/2 - 6s - loss: 0.3079 - acc: 0.8167 - val_loss: 0.2990 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 45/120\n",
      "2/2 - 6s - loss: 0.3313 - acc: 0.8000 - val_loss: 0.3818 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 46/120\n",
      "2/2 - 6s - loss: 0.3530 - acc: 0.8167 - val_loss: 0.3115 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 47/120\n",
      "2/2 - 6s - loss: 0.3745 - acc: 0.8000 - val_loss: 0.3171 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 48/120\n",
      "2/2 - 6s - loss: 0.2977 - acc: 0.8500 - val_loss: 0.3114 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 49/120\n",
      "2/2 - 6s - loss: 0.3223 - acc: 0.8667 - val_loss: 0.3131 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 50/120\n",
      "2/2 - 6s - loss: 0.3672 - acc: 0.8167 - val_loss: 0.3057 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 51/120\n",
      "2/2 - 6s - loss: 0.3196 - acc: 0.8333 - val_loss: 0.3579 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 52/120\n",
      "2/2 - 6s - loss: 0.3686 - acc: 0.8000 - val_loss: 0.3593 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 53/120\n",
      "2/2 - 6s - loss: 0.3489 - acc: 0.8333 - val_loss: 0.3284 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 54/120\n",
      "2/2 - 6s - loss: 0.3482 - acc: 0.8167 - val_loss: 0.3801 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 55/120\n",
      "2/2 - 6s - loss: 0.4620 - acc: 0.7500 - val_loss: 0.3154 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 56/120\n",
      "2/2 - 6s - loss: 0.3263 - acc: 0.8167 - val_loss: 0.6897 - val_acc: 0.6667 - 6s/epoch - 3s/step\n",
      "Epoch 57/120\n",
      "2/2 - 6s - loss: 0.5057 - acc: 0.7167 - val_loss: 0.3114 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 58/120\n",
      "2/2 - 6s - loss: 0.3140 - acc: 0.8500 - val_loss: 0.6837 - val_acc: 0.7333 - 6s/epoch - 3s/step\n",
      "Epoch 59/120\n",
      "2/2 - 6s - loss: 0.5155 - acc: 0.7833 - val_loss: 0.3335 - val_acc: 0.8000 - 6s/epoch - 3s/step\n",
      "Epoch 60/120\n",
      "2/2 - 6s - loss: 0.3009 - acc: 0.8500 - val_loss: 0.3382 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 61/120\n",
      "2/2 - 6s - loss: 0.3935 - acc: 0.7833 - val_loss: 0.3989 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 62/120\n",
      "2/2 - 6s - loss: 0.3594 - acc: 0.8167 - val_loss: 0.3287 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 63/120\n",
      "2/2 - 6s - loss: 0.3326 - acc: 0.8167 - val_loss: 0.3357 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 64/120\n",
      "2/2 - 6s - loss: 0.3672 - acc: 0.7833 - val_loss: 0.3503 - val_acc: 0.7833 - 6s/epoch - 3s/step\n",
      "Epoch 65/120\n",
      "2/2 - 6s - loss: 0.3404 - acc: 0.8167 - val_loss: 0.3337 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 66/120\n",
      "2/2 - 6s - loss: 0.3218 - acc: 0.8667 - val_loss: 0.3240 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 67/120\n",
      "2/2 - 6s - loss: 0.3294 - acc: 0.8167 - val_loss: 0.3304 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 68/120\n",
      "2/2 - 6s - loss: 0.3223 - acc: 0.8167 - val_loss: 0.3262 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 69/120\n",
      "2/2 - 6s - loss: 0.3396 - acc: 0.8167 - val_loss: 0.3160 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 70/120\n",
      "2/2 - 6s - loss: 0.3043 - acc: 0.8500 - val_loss: 0.3219 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 71/120\n",
      "2/2 - 6s - loss: 0.3317 - acc: 0.8167 - val_loss: 0.3239 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 72/120\n",
      "2/2 - 6s - loss: 0.3478 - acc: 0.8333 - val_loss: 0.3107 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 73/120\n",
      "2/2 - 6s - loss: 0.2926 - acc: 0.8667 - val_loss: 0.3124 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 74/120\n",
      "2/2 - 6s - loss: 0.3355 - acc: 0.8333 - val_loss: 0.3197 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 75/120\n",
      "2/2 - 6s - loss: 0.2993 - acc: 0.8500 - val_loss: 0.3153 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 76/120\n",
      "2/2 - 6s - loss: 0.3152 - acc: 0.8667 - val_loss: 0.3136 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 77/120\n",
      "2/2 - 6s - loss: 0.3240 - acc: 0.8333 - val_loss: 0.2987 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 78/120\n",
      "2/2 - 6s - loss: 0.3074 - acc: 0.8333 - val_loss: 0.3130 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 79/120\n",
      "2/2 - 6s - loss: 0.3549 - acc: 0.8000 - val_loss: 0.3123 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 80/120\n",
      "2/2 - 6s - loss: 0.2959 - acc: 0.8500 - val_loss: 0.3196 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 81/120\n",
      "2/2 - 6s - loss: 0.3000 - acc: 0.8500 - val_loss: 0.3196 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 82/120\n",
      "2/2 - 6s - loss: 0.2944 - acc: 0.8667 - val_loss: 0.3040 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 83/120\n",
      "2/2 - 6s - loss: 0.3067 - acc: 0.8500 - val_loss: 0.3077 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 84/120\n",
      "2/2 - 6s - loss: 0.3163 - acc: 0.8167 - val_loss: 0.3027 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 85/120\n",
      "2/2 - 5s - loss: 0.3060 - acc: 0.8667 - val_loss: 0.3017 - val_acc: 0.8500 - 5s/epoch - 3s/step\n",
      "Epoch 86/120\n",
      "2/2 - 6s - loss: 0.3032 - acc: 0.8333 - val_loss: 0.3060 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 87/120\n",
      "2/2 - 6s - loss: 0.3181 - acc: 0.8167 - val_loss: 0.2989 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 88/120\n",
      "2/2 - 6s - loss: 0.2701 - acc: 0.8500 - val_loss: 0.2858 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 89/120\n",
      "2/2 - 6s - loss: 0.2968 - acc: 0.9000 - val_loss: 0.2971 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 90/120\n",
      "2/2 - 6s - loss: 0.3083 - acc: 0.8500 - val_loss: 0.3000 - val_acc: 0.8333 - 6s/epoch - 3s/step\n",
      "Epoch 91/120\n",
      "2/2 - 6s - loss: 0.2789 - acc: 0.8833 - val_loss: 0.2815 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 92/120\n",
      "2/2 - 6s - loss: 0.2832 - acc: 0.8500 - val_loss: 0.2856 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 93/120\n",
      "2/2 - 6s - loss: 0.3297 - acc: 0.8333 - val_loss: 0.2960 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 94/120\n",
      "2/2 - 6s - loss: 0.3009 - acc: 0.8667 - val_loss: 0.2689 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 95/120\n",
      "2/2 - 6s - loss: 0.2881 - acc: 0.8333 - val_loss: 0.2977 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 96/120\n",
      "2/2 - 6s - loss: 0.2946 - acc: 0.8500 - val_loss: 0.2750 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 97/120\n",
      "2/2 - 6s - loss: 0.2700 - acc: 0.8667 - val_loss: 0.2696 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 98/120\n",
      "2/2 - 6s - loss: 0.3142 - acc: 0.8667 - val_loss: 0.2516 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 99/120\n",
      "2/2 - 6s - loss: 0.2873 - acc: 0.8833 - val_loss: 0.2712 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 100/120\n",
      "2/2 - 6s - loss: 0.2560 - acc: 0.8667 - val_loss: 0.2812 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 101/120\n",
      "2/2 - 6s - loss: 0.2792 - acc: 0.8500 - val_loss: 0.2621 - val_acc: 0.9000 - 6s/epoch - 3s/step\n",
      "Epoch 102/120\n",
      "2/2 - 6s - loss: 0.2954 - acc: 0.9000 - val_loss: 0.2823 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 103/120\n",
      "2/2 - 6s - loss: 0.2826 - acc: 0.8667 - val_loss: 0.3056 - val_acc: 0.8167 - 6s/epoch - 3s/step\n",
      "Epoch 104/120\n",
      "2/2 - 6s - loss: 0.3365 - acc: 0.8333 - val_loss: 0.2816 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 105/120\n",
      "2/2 - 6s - loss: 0.2909 - acc: 0.8500 - val_loss: 0.2791 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 106/120\n",
      "2/2 - 6s - loss: 0.2593 - acc: 0.9167 - val_loss: 0.2619 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 107/120\n",
      "2/2 - 6s - loss: 0.2905 - acc: 0.8167 - val_loss: 0.3460 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 108/120\n",
      "2/2 - 6s - loss: 0.3147 - acc: 0.8500 - val_loss: 0.2589 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 109/120\n",
      "2/2 - 6s - loss: 0.2663 - acc: 0.8667 - val_loss: 0.2698 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 110/120\n",
      "2/2 - 6s - loss: 0.2732 - acc: 0.8833 - val_loss: 0.2906 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 111/120\n",
      "2/2 - 6s - loss: 0.3078 - acc: 0.8500 - val_loss: 0.2785 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 112/120\n",
      "2/2 - 6s - loss: 0.2736 - acc: 0.8667 - val_loss: 0.2959 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 113/120\n",
      "2/2 - 6s - loss: 0.3003 - acc: 0.8500 - val_loss: 0.2668 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 114/120\n",
      "2/2 - 6s - loss: 0.2889 - acc: 0.8500 - val_loss: 0.2769 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 115/120\n",
      "2/2 - 6s - loss: 0.2607 - acc: 0.8667 - val_loss: 0.2989 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 116/120\n",
      "2/2 - 6s - loss: 0.2761 - acc: 0.8667 - val_loss: 0.2559 - val_acc: 0.8833 - 6s/epoch - 3s/step\n",
      "Epoch 117/120\n",
      "2/2 - 6s - loss: 0.2698 - acc: 0.8500 - val_loss: 0.2864 - val_acc: 0.8667 - 6s/epoch - 3s/step\n",
      "Epoch 118/120\n",
      "2/2 - 6s - loss: 0.2834 - acc: 0.9000 - val_loss: 0.2501 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 119/120\n",
      "2/2 - 6s - loss: 0.2772 - acc: 0.8667 - val_loss: 0.2931 - val_acc: 0.8500 - 6s/epoch - 3s/step\n",
      "Epoch 120/120\n",
      "2/2 - 6s - loss: 0.2767 - acc: 0.8667 - val_loss: 0.2369 - val_acc: 0.8833 - 6s/epoch - 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Wsave = model_alexnet.get_weights()\n",
    "for times in range(12):\n",
    "    epo = (times+1)*10\n",
    "    model_alexnet.set_weights(Wsave)\n",
    "    model_alexnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc'])\n",
    "    history = model_alexnet.fit(train_generator,validation_data=val_generator,epochs=epo, verbose = 2)\n",
    "\n",
    "    f = open(\"alexnet.csv\", \"a\")\n",
    "    f.write(\"\\n\"+str(epo)+\",\"+\n",
    "        str(history.history['loss'][-1])+\",\"+\n",
    "        str(history.history['val_loss'][-1])+\",\"+\n",
    "        str(history.history['acc'][-1])+\",\"+\n",
    "        str(history.history['val_acc'][-1])\n",
    "    )\n",
    "    f.close()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss Model')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./alexnet/loss_'+str(epo)+'.png')\n",
    "    plt.cla()\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./alexnet/acc_'+str(epo)+'.png')\n",
    "    \n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "863388641bf8518efc9f9c13edbd8c5a9191560a3a7c90c25b6128b1c338502d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "220b59355a8dadb4ba3bf77e4f9773cad1e54b32290f811d9d316f35385cbe26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
